{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51244f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando datos de ventas: 100%|██████████| 897/897 [15:12<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjuntos de datos generados y guardados como CSV.\n",
      "Total de ventas: 199909\n",
      "Total de productos: 40\n",
      "Total de entradas de historial de precios: 1200\n",
      "Total de clientes: 2000\n",
      "Total de regiones: 10\n",
      "Total de canales: 5\n",
      "Total de promociones: 20\n",
      "Total de entradas de inventario: 120\n",
      "\n",
      "Verificación de variación mensual (primeros 5 productos):\n",
      "Producto 1:\n",
      "  2023-1 a 2023-2: -4.87%\n",
      "  2023-2 a 2023-3: 18.17%\n",
      "  2023-3 a 2023-4: -12.41%\n",
      "  2023-4 a 2023-5: 9.22%\n",
      "  2023-5 a 2023-6: -1.06%\n",
      "  2023-6 a 2023-7: -12.43%\n",
      "  2023-7 a 2023-8: -21.36%\n",
      "  2023-8 a 2023-9: -5.43%\n",
      "  2023-9 a 2023-10: -5.58%\n",
      "  2023-10 a 2023-11: 0.35%\n",
      "  2023-11 a 2023-12: 17.60%\n",
      "  2023-12 a 2024-1: -13.15%\n",
      "  2024-1 a 2024-2: 2.67%\n",
      "  2024-2 a 2024-3: 12.45%\n",
      "  2024-3 a 2024-4: 1.73%\n",
      "  2024-4 a 2024-5: 2.91%\n",
      "  2024-5 a 2024-6: -17.03%\n",
      "  2024-6 a 2024-7: 1.61%\n",
      "  2024-7 a 2024-8: -14.62%\n",
      "  2024-8 a 2024-9: -17.17%\n",
      "  2024-9 a 2024-10: 28.99%\n",
      "  2024-10 a 2024-11: -2.98%\n",
      "  2024-11 a 2024-12: 15.60%\n",
      "  2024-12 a 2025-1: 0.59%\n",
      "  2025-1 a 2025-2: -6.93%\n",
      "  2025-2 a 2025-3: 16.03%\n",
      "  2025-3 a 2025-4: -1.90%\n",
      "  2025-4 a 2025-5: 6.67%\n",
      "  2025-5 a 2025-6: -53.95%\n",
      "Producto 2:\n",
      "  2023-1 a 2023-2: 3.73%\n",
      "  2023-2 a 2023-3: 13.71%\n",
      "  2023-3 a 2023-4: -2.98%\n",
      "  2023-4 a 2023-5: -0.79%\n",
      "  2023-5 a 2023-6: 17.48%\n",
      "  2023-6 a 2023-7: 25.36%\n",
      "  2023-7 a 2023-8: 4.41%\n",
      "  2023-8 a 2023-9: -7.12%\n",
      "  2023-9 a 2023-10: -3.15%\n",
      "  2023-10 a 2023-11: 3.07%\n",
      "  2023-11 a 2023-12: 5.83%\n",
      "  2023-12 a 2024-1: -9.61%\n",
      "  2024-1 a 2024-2: -6.21%\n",
      "  2024-2 a 2024-3: 1.32%\n",
      "  2024-3 a 2024-4: -10.62%\n",
      "  2024-4 a 2024-5: -1.40%\n",
      "  2024-5 a 2024-6: 22.19%\n",
      "  2024-6 a 2024-7: 12.71%\n",
      "  2024-7 a 2024-8: 1.81%\n",
      "  2024-8 a 2024-9: -6.78%\n",
      "  2024-9 a 2024-10: -5.90%\n",
      "  2024-10 a 2024-11: -1.68%\n",
      "  2024-11 a 2024-12: 6.59%\n",
      "  2024-12 a 2025-1: -4.62%\n",
      "  2025-1 a 2025-2: -11.04%\n",
      "  2025-2 a 2025-3: -11.33%\n",
      "  2025-3 a 2025-4: -7.42%\n",
      "  2025-4 a 2025-5: 4.61%\n",
      "  2025-5 a 2025-6: -38.62%\n",
      "Producto 3:\n",
      "  2023-1 a 2023-2: 3.79%\n",
      "  2023-2 a 2023-3: 15.16%\n",
      "  2023-3 a 2023-4: -13.96%\n",
      "  2023-4 a 2023-5: -0.81%\n",
      "  2023-5 a 2023-6: 3.92%\n",
      "  2023-6 a 2023-7: -11.90%\n",
      "  2023-7 a 2023-8: -10.69%\n",
      "  2023-8 a 2023-9: -12.59%\n",
      "  2023-9 a 2023-10: -0.77%\n",
      "  2023-10 a 2023-11: -7.64%\n",
      "  2023-11 a 2023-12: 2.13%\n",
      "  2023-12 a 2024-1: -7.80%\n",
      "  2024-1 a 2024-2: 2.40%\n",
      "  2024-2 a 2024-3: 25.95%\n",
      "  2024-3 a 2024-4: -7.61%\n",
      "  2024-4 a 2024-5: 6.04%\n",
      "  2024-5 a 2024-6: -8.24%\n",
      "  2024-6 a 2024-7: -3.60%\n",
      "  2024-7 a 2024-8: -22.05%\n",
      "  2024-8 a 2024-9: -13.16%\n",
      "  2024-9 a 2024-10: 11.09%\n",
      "  2024-10 a 2024-11: -2.46%\n",
      "  2024-11 a 2024-12: 8.36%\n",
      "  2024-12 a 2025-1: -1.22%\n",
      "  2025-1 a 2025-2: -0.55%\n",
      "  2025-2 a 2025-3: 42.58%\n",
      "  2025-3 a 2025-4: 7.10%\n",
      "  2025-4 a 2025-5: 2.72%\n",
      "  2025-5 a 2025-6: -49.68%\n",
      "Producto 4:\n",
      "  2023-1 a 2023-2: -4.87%\n",
      "  2023-2 a 2023-3: 15.48%\n",
      "  2023-3 a 2023-4: 7.00%\n",
      "  2023-4 a 2023-5: 1.93%\n",
      "  2023-5 a 2023-6: 14.89%\n",
      "  2023-6 a 2023-7: 16.90%\n",
      "  2023-7 a 2023-8: 2.56%\n",
      "  2023-8 a 2023-9: -5.31%\n",
      "  2023-9 a 2023-10: -10.32%\n",
      "  2023-10 a 2023-11: -6.66%\n",
      "  2023-11 a 2023-12: 9.81%\n",
      "  2023-12 a 2024-1: -4.56%\n",
      "  2024-1 a 2024-2: -12.51%\n",
      "  2024-2 a 2024-3: -1.16%\n",
      "  2024-3 a 2024-4: 2.20%\n",
      "  2024-4 a 2024-5: 2.97%\n",
      "  2024-5 a 2024-6: 10.90%\n",
      "  2024-6 a 2024-7: 9.85%\n",
      "  2024-7 a 2024-8: 10.22%\n",
      "  2024-8 a 2024-9: -10.31%\n",
      "  2024-9 a 2024-10: -2.45%\n",
      "  2024-10 a 2024-11: -4.50%\n",
      "  2024-11 a 2024-12: 23.46%\n",
      "  2024-12 a 2025-1: -8.97%\n",
      "  2025-1 a 2025-2: -23.55%\n",
      "  2025-2 a 2025-3: 8.05%\n",
      "  2025-3 a 2025-4: -11.49%\n",
      "  2025-4 a 2025-5: 11.71%\n",
      "  2025-5 a 2025-6: -45.18%\n",
      "Producto 5:\n",
      "  2023-1 a 2023-2: 0.15%\n",
      "  2023-2 a 2023-3: 18.26%\n",
      "  2023-3 a 2023-4: -3.27%\n",
      "  2023-4 a 2023-5: 4.62%\n",
      "  2023-5 a 2023-6: 16.88%\n",
      "  2023-6 a 2023-7: 11.40%\n",
      "  2023-7 a 2023-8: 5.25%\n",
      "  2023-8 a 2023-9: -4.22%\n",
      "  2023-9 a 2023-10: -8.34%\n",
      "  2023-10 a 2023-11: 2.78%\n",
      "  2023-11 a 2023-12: 2.87%\n",
      "  2023-12 a 2024-1: -5.39%\n",
      "  2024-1 a 2024-2: -7.14%\n",
      "  2024-2 a 2024-3: 7.01%\n",
      "  2024-3 a 2024-4: -2.97%\n",
      "  2024-4 a 2024-5: 7.93%\n",
      "  2024-5 a 2024-6: 23.87%\n",
      "  2024-6 a 2024-7: 12.80%\n",
      "  2024-7 a 2024-8: -1.25%\n",
      "  2024-8 a 2024-9: -0.53%\n",
      "  2024-9 a 2024-10: -5.49%\n",
      "  2024-10 a 2024-11: -4.58%\n",
      "  2024-11 a 2024-12: 6.98%\n",
      "  2024-12 a 2025-1: -6.97%\n",
      "  2025-1 a 2025-2: -15.93%\n",
      "  2025-2 a 2025-3: 6.79%\n",
      "  2025-3 a 2025-4: -0.61%\n",
      "  2025-4 a 2025-5: -0.62%\n",
      "  2025-5 a 2025-6: -38.63%\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# Iniciar Faker\n",
    "fake = Faker('es_CO')\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# --- Parámetros ---\n",
    "n_ventas = 150000\n",
    "n_clientes = 1500\n",
    "n_canales = 5\n",
    "n_promociones = 50\n",
    "n_regiones = 5\n",
    "\n",
    "start_date_data = datetime(2023, 1, 1)\n",
    "end_date_data = datetime(2025, 5, 31)\n",
    "\n",
    "# Parámetros de Elasticidad\n",
    "elasticidades_por_categoria = {\n",
    "    'Agua': {'min': -0.5, 'max': -0.8},\n",
    "    'Gaseosa': {'min': -1.0, 'max': -1.2},\n",
    "    'Jugo': {'min': -0.6, 'max': -0.95},\n",
    "    'Bebida de Té': {'min': -1.0, 'max': -1.5},\n",
    "    'Bebida Energética': {'min': -1.5, 'max': -2.5}\n",
    "}\n",
    "prob_elasticidad_positiva = 0.05\n",
    "rango_elasticidad_positiva = {'min': 0.05, 'max': 0.2}\n",
    "\n",
    "# --- Parámetros de Control de Fluctuación ---\n",
    "MAX_PERCENT_CHANGE_PER_MONTH_PRODUCT_AGGREGATE = 0.12\n",
    "MIN_QUANTITY_PER_SALE = 24\n",
    "MAX_QUANTITY_PER_SALE = 120\n",
    "DAILY_QUANTITY_FLUCTUATION_FACTOR = 0.05\n",
    "\n",
    "# --- Ajuste de Temporalidad ---\n",
    "seasonal_multipliers = {\n",
    "    1: random.uniform(0.95, 1.00),\n",
    "    2: random.uniform(0.95, 1.00),\n",
    "    3: random.uniform(0.95, 1.00),\n",
    "    4: random.uniform(0.95, 1.00),\n",
    "    5: random.uniform(0.95, 1.00),\n",
    "    6: random.uniform(1.35, 1.50),\n",
    "    7: random.uniform(1.50, 1.65),\n",
    "    8: random.uniform(1.45, 1.60),\n",
    "    9: random.uniform(0.95, 1.00),\n",
    "    10: random.uniform(0.95, 1.00),\n",
    "    11: random.uniform(1.00, 1.10),\n",
    "    12: random.uniform(1.50, 1.70)\n",
    "}\n",
    "\n",
    "# --- Parámetros deImpacto en las Promociones ---\n",
    "PROMOTION_ELASTICITY_MULTIPLIER = 1.5\n",
    "MIN_PROMOTION_BOOST = 1.2\n",
    "MAX_PROMOTION_BOOST = 1.8\n",
    "\n",
    "# --- 1. Tabla Región---\n",
    "ciudades_colombia = [\n",
    "    {\"nombre_region\": \"Cundinamarca\", \"ciudad\": \"Bogotá\", \"latitud\": 4.7110, \"longitud\": -74.0721},\n",
    "    {\"nombre_region\": \"Antioquia\", \"ciudad\": \"Medellín\", \"latitud\": 6.2442, \"longitud\": -75.5812},\n",
    "    {\"nombre_region\": \"Valle del Cauca\", \"ciudad\": \"Cali\", \"latitud\": 3.4516, \"longitud\": -76.5320},\n",
    "    {\"nombre_region\": \"Atlántico\", \"ciudad\": \"Barranquilla\", \"latitud\": 10.9685, \"longitud\": -74.7813},\n",
    "    {\"nombre_region\": \"Bolívar\", \"ciudad\": \"Cartagena\", \"latitud\": 10.3910, \"longitud\": -75.4794}\n",
    "]\n",
    "\n",
    "regiones_data = []\n",
    "for i in tqdm(range(n_regiones), desc=\"Generando regiones\", mininterval=1):\n",
    "    region_info = ciudades_colombia[i] if i < len(ciudades_colombia) else random.choice(ciudades_colombia)\n",
    "    regiones_data.append({\n",
    "        'region_id': i + 1,\n",
    "        'nombre_region': region_info['nombre_region'],\n",
    "        'ciudad': region_info['ciudad'],\n",
    "        'latitud': region_info['latitud'],\n",
    "        'longitud': region_info['longitud']\n",
    "    })\n",
    "df_regiones = pl.DataFrame(regiones_data)\n",
    "\n",
    "# Pesos de las regiones para la selección de clientes (simulando una distribución poblacional)\n",
    "pesos_regiones = {\n",
    "    \"Bogotá\": 0.20, \"Medellín\": 0.25, \"Cali\": 0.15, \"Barranquilla\": 0.15,\n",
    "    \"Cartagena\": 0.10, \"Bucaramanga\": 0.05, \"Cúcuta\": 0.04, \"Ibagué\": 0.03\n",
    "}\n",
    "prob_regiones_para_seleccion = np.array([pesos_regiones.get(row['ciudad'], 0.01) for row in df_regiones.iter_rows(named=True)])\n",
    "prob_regiones_para_seleccion /= prob_regiones_para_seleccion.sum()\n",
    "regiones_para_seleccion = df_regiones['region_id'].to_list()\n",
    "\n",
    "# --- 2. Tabla Clientes ---\n",
    "ciudades_regiones = df_regiones['ciudad'].to_list()\n",
    "fecha_actual = end_date_data\n",
    "fecha_365_dias_atras = fecha_actual - timedelta(days=365)\n",
    "\n",
    "porcentaje_inactivos = random.uniform(0.05, 0.15)\n",
    "n_clientes_inactivos = int(n_clientes * porcentaje_inactivos)\n",
    "n_clientes_activos = n_clientes - n_clientes_inactivos\n",
    "\n",
    "# Mapeo de region_id\n",
    "ciudad_to_region_id = {row['ciudad']: row['region_id'] for row in df_regiones.iter_rows(named=True)}\n",
    "\n",
    "clientes = []\n",
    "for i in tqdm(range(1, n_clientes + 1), desc=\"Generando clientes\", mininterval=1):\n",
    "    es_inactivo = i <= n_clientes_inactivos\n",
    "    \n",
    "    if es_inactivo:\n",
    "        ultima_compra = fake.date_between(\n",
    "            start_date=fecha_actual - timedelta(days=730),\n",
    "            end_date=fecha_365_dias_atras\n",
    "        )\n",
    "        base_frecuencia = np.random.randint(1, 5)\n",
    "    else:\n",
    "        ultima_compra = fake.date_between(\n",
    "            start_date=fecha_365_dias_atras,\n",
    "            end_date=fecha_actual\n",
    "        )\n",
    "        base_frecuencia = np.random.randint(5, 15)\n",
    "        base_frecuencia = min(base_frecuencia, 30)\n",
    "\n",
    "    ciudad = np.random.choice(ciudades_regiones, p=prob_regiones_para_seleccion)\n",
    "    region_id = ciudad_to_region_id[ciudad]\n",
    "\n",
    "    clientes.append({\n",
    "        'cliente_id': i,\n",
    "        'nombre': fake.name(),\n",
    "        'edad': np.random.randint(18, 80),\n",
    "        'genero': np.random.choice(['M', 'F']),\n",
    "        'ciudad': ciudad,\n",
    "        'region_id': region_id,\n",
    "        'frecuencia_compra': base_frecuencia,\n",
    "        'ultima_compra': ultima_compra\n",
    "    })\n",
    "df_clientes = pl.DataFrame(clientes)\n",
    "\n",
    "# --- 3. Tabla de Promociones ---\n",
    "promociones_data = []\n",
    "for i in tqdm(range(1, n_promociones + 1), desc=\"Generando promociones\", mininterval=1):\n",
    "    fecha_inicio = fake.date_between(start_date=start_date_data - timedelta(days=180), end_date=end_date_data - timedelta(days=90))\n",
    "    fecha_fin = fecha_inicio + timedelta(days=random.randint(30, 180))\n",
    "\n",
    "    if fecha_fin > end_date_data.date():\n",
    "        fecha_fin = end_date_data.date()\n",
    "\n",
    "    promociones_data.append({\n",
    "        'promocion_id': i,\n",
    "        'nombre_promocion': f\"Promo {i}\",\n",
    "        'descuento_porcentaje': np.random.randint(5, 30),\n",
    "        'fecha_inicio': fecha_inicio,\n",
    "        'fecha_fin': fecha_fin\n",
    "    })\n",
    "df_promociones = pl.DataFrame(promociones_data)\n",
    "\n",
    "# Actualizando df_clientes con sensibilidad a promociones\n",
    "avg_promotion_discount = df_promociones['descuento_porcentaje'].mean() / 100\n",
    "clientes_updated = []\n",
    "for cliente in tqdm(df_clientes.iter_rows(named=True), desc=\"Actualizando clientes con promociones\", mininterval=1):\n",
    "    base_frecuencia = cliente['frecuencia_compra']\n",
    "    if cliente['cliente_id'] > n_clientes_inactivos:\n",
    "        promotion_sensitivity = 1 + (avg_promotion_discount * random.uniform(0.5, 1.5))\n",
    "        base_frecuencia = int(base_frecuencia * promotion_sensitivity)\n",
    "        base_frecuencia = min(base_frecuencia, 30)\n",
    "    clientes_updated.append({\n",
    "        **cliente,\n",
    "        'frecuencia_compra': base_frecuencia\n",
    "    })\n",
    "df_clientes = pl.DataFrame(clientes_updated)\n",
    "\n",
    "# Generar client_id y region_id para mapear tabla de ventas\n",
    "client_to_region_id = {row['cliente_id']: row['region_id'] for row in df_clientes.select(['cliente_id', 'region_id']).iter_rows(named=True)}\n",
    "\n",
    "# --- 4. Tabla Productos ---\n",
    "volumenes_gaseosa_jugo_ml = [250, 600, 1500]\n",
    "unidades_por_caja_gaseosa_jugo = [1, 6]\n",
    "volumenes_energia_ml = [250, 500]\n",
    "unidades_por_caja_energia = [1, 6]\n",
    "volumenes_agua_ml = [500, 1000, 5000]\n",
    "unidades_por_caja_agua = [1, 6]\n",
    "volumenes_te_ml = [300, 500]\n",
    "unidades_por_caja_te = [1, 6]\n",
    "\n",
    "categorias_marcas_sabor_base = [\n",
    "    {'categoria_base': 'Gaseosa', 'sabores': ['Cola', 'Naranja', 'Limón'], 'marcas': ['Zulianita', 'SaborMax', 'Coca-Loca']},\n",
    "    {'categoria_base': 'Bebida de Té', 'sabores': ['Té Negro', 'Té Verde'], 'marcas': ['Zulianita', 'TeaVida', 'Coca-Loca']},\n",
    "    #{'categoria_base': 'Jugo', 'sabores': ['Jugo de Naranja', 'Jugo de Manzana'], 'marcas': ['Zulianita', 'FrutaFresca', 'Coca-Loca']},\n",
    "    {'categoria_base': 'Bebida Energética', 'sabores': ['Booster Guaraná'], 'marcas': ['Zulianita', 'EnergyBoost', 'Coca-Loca']},\n",
    "    {'categoria_base': 'Agua', 'sabores': ['Con Gas', 'Sin Gas'], 'marcas': ['Zulianita', 'AquaPura', 'Coca-Loca']}\n",
    "]\n",
    "\n",
    "producto_nombres_unicos = set()\n",
    "productos = []\n",
    "producto_id = 1\n",
    "\n",
    "for categoria in tqdm(categorias_marcas_sabor_base, desc=\"Generando productos\", mininterval=1, leave=False):\n",
    "    categoria_base = categoria['categoria_base']\n",
    "    sabores = categoria['sabores']\n",
    "    marcas = categoria['marcas']\n",
    "    \n",
    "    if categoria_base in ['Gaseosa']:\n",
    "        volumenes = volumenes_gaseosa_jugo_ml\n",
    "        unidades_caja = unidades_por_caja_gaseosa_jugo\n",
    "    elif categoria_base == 'Bebida Energética':\n",
    "        volumenes = volumenes_energia_ml\n",
    "        unidades_caja = unidades_por_caja_energia\n",
    "    elif categoria_base == 'Agua':\n",
    "        volumenes = volumenes_agua_ml\n",
    "        unidades_caja = unidades_por_caja_agua\n",
    "    else:\n",
    "        volumenes = volumenes_te_ml\n",
    "        unidades_caja = unidades_por_caja_te\n",
    "\n",
    "    for marca in marcas:\n",
    "        combinations = list(itertools.product(sabores, volumenes, unidades_caja))\n",
    "        \n",
    "        category_products = 0\n",
    "        for sabor, volumen_ml_val, unidades_caja_val in combinations:\n",
    "            if categoria_base == 'Agua':\n",
    "                nombre_base = f'ACHE2O {sabor}' if marca == 'Zulianita' else f'{sabor} {marca}'\n",
    "            elif categoria_base == 'Bebida Energética':\n",
    "                nombre_base = f'Power Cell {sabor}' if marca == 'Zulianita' else f'{sabor} {marca}'\n",
    "            elif categoria_base == 'Bebida de Té':\n",
    "                nombre_base = f'{sabor} Zulianita' if marca == 'Zulianita' else f'{sabor} {marca}'\n",
    "           # elif categoria_base == 'Jugo':\n",
    "            #    nombre_base = sabor if marca == 'Zulianita' else f'{sabor} {marca}'\n",
    "            else:\n",
    "                nombre_base = f'Zulianita {sabor}' if marca == 'Zulianita' else f'{sabor} {marca}'\n",
    "            \n",
    "            nombre_producto_str = f'{nombre_base} {volumen_ml_val // 1000}L x {unidades_caja_val}uds' if volumen_ml_val >= 1000 else f'{nombre_base} {volumen_ml_val}mL x {unidades_caja_val}uds'\n",
    "            \n",
    "            if nombre_producto_str in producto_nombres_unicos:\n",
    "                print(f\"Advertencia: Nombre duplicado '{nombre_producto_str}' en {categoria_base}, marca {marca}. Saltando...\")\n",
    "                continue\n",
    "            \n",
    "            producto_nombres_unicos.add(nombre_producto_str)\n",
    "            productos.append({\n",
    "                'producto_id': producto_id,\n",
    "                'nombre_producto': nombre_producto_str,\n",
    "                'categoria': categoria_base,\n",
    "                'marca': marca,\n",
    "                'volumen_ml_base': volumen_ml_val,\n",
    "                'unidades_caja_base': unidades_caja_val\n",
    "            })\n",
    "            producto_id += 1\n",
    "            category_products += 1\n",
    "        \n",
    "        print(f\"Generados {category_products} productos para {categoria_base}, marca {marca}\")\n",
    "\n",
    "df_productos = pl.DataFrame(productos)\n",
    "n_productos = len(df_productos)\n",
    "print(f\"Total de productos generados: {n_productos}\")\n",
    "\n",
    "# --- 5. Tabla Historial de Precios ---\n",
    "historico_precios = []\n",
    "hist_precio_id_counter = 1\n",
    "\n",
    "precios_por_ml_base_categoria = {\n",
    "    'Agua': 2.5, 'Gaseosa': 3.5, 'Jugo': 4.0, 'Bebida Energética': 10.0, 'Bebida de Té': 6.0\n",
    "}\n",
    "costos_por_ml_base_categoria = {\n",
    "    'Agua': 1.0, 'Gaseosa': 1.8, 'Jugo': 2.8, 'Bebida Energética': 6.5, 'Bebida de Té': 3.8\n",
    "}\n",
    "\n",
    "total_price_records = n_productos * 29\n",
    "for producto_row in tqdm(df_productos.iter_rows(named=True), desc=\"Generando historico de precios\", total=n_productos, mininterval=1):\n",
    "    current_date = start_date_data.replace(day=1)\n",
    "    volumen_para_calculo = producto_row['volumen_ml_base'] if producto_row['volumen_ml_base'] > 0 else 1000\n",
    "    unidades_para_calculo = producto_row['unidades_caja_base'] if producto_row['unidades_caja_base'] > 0 else 1\n",
    "    categoria = producto_row['categoria']\n",
    "\n",
    "    base_precio_ml_actual = precios_por_ml_base_categoria.get(categoria, 3.0)\n",
    "    base_costo_ml_actual = costos_por_ml_base_categoria.get(categoria, 1.8)\n",
    "\n",
    "    initial_precio_unitario = round(base_precio_ml_actual * volumen_para_calculo * unidades_para_calculo, 2)\n",
    "    initial_costo_variable = round(base_costo_ml_actual * volumen_para_calculo * unidades_para_calculo, 2)\n",
    "\n",
    "    while current_date <= end_date_data:\n",
    "        historico_precios.append({\n",
    "            'historico_precio_id': hist_precio_id_counter,\n",
    "            'producto_id': producto_row['producto_id'],\n",
    "            'fecha_actualizacion': current_date.date(),\n",
    "            'precio_base': initial_precio_unitario,\n",
    "            'costo_variable': initial_costo_variable\n",
    "        })\n",
    "        hist_precio_id_counter += 1\n",
    "\n",
    "        incremento_porcentaje_precio = random.uniform(0.00, 0.015)\n",
    "        incremento_porcentaje_costo = random.uniform(0.00, 0.015)\n",
    "\n",
    "        initial_precio_unitario = round(initial_precio_unitario * (1 + incremento_porcentaje_precio), 2)\n",
    "        initial_costo_variable = round(initial_costo_variable * (1 + incremento_porcentaje_costo), 2)\n",
    "\n",
    "        if initial_costo_variable >= initial_precio_unitario:\n",
    "            initial_costo_variable = round(initial_precio_unitario * 0.7, 2)\n",
    "\n",
    "        if current_date.month == 12:\n",
    "            current_date = current_date.replace(year=current_date.year + 1, month=1)\n",
    "        else:\n",
    "            current_date = current_date.replace(month=current_date.month + 1)\n",
    "\n",
    "df_historico_precios = pl.DataFrame(historico_precios)\n",
    "\n",
    "# --- 6. Tabla Canales ---\n",
    "canales = {\n",
    "    'canal_id': range(1, n_canales + 1),\n",
    "    'nombre_canal': ['Supermercado', 'Tienda de Conveniencia', 'E-commerce', 'Farmacia', 'Hipermercado'],\n",
    "    'tipo_canal': ['Físico', 'Físico', 'Online', 'Físico', 'Físico']\n",
    "}\n",
    "df_canales = pl.DataFrame({k: list(v) for k, v in tqdm(canales.items(), desc=\"Generando canales\", total=len(canales), mininterval=1)})\n",
    "\n",
    "def get_channel_weights(current_date):\n",
    "    weights = {\n",
    "        'Supermercado': 0.40,\n",
    "        'Tienda de Conveniencia': 0.20,\n",
    "        'E-commerce': 0.15,\n",
    "        'Farmacia': 0.05,\n",
    "        'Hipermercado': 0.35\n",
    "    }\n",
    "    total_weight = sum(weights.values())\n",
    "    return {k: v / total_weight for k, v in weights.items()}\n",
    "\n",
    "# --- 7. Tabla Inventario---\n",
    "zulianita_product_ids = df_productos.filter(pl.col('marca') == 'Zulianita')['producto_id'].to_list()\n",
    "n_months = 12\n",
    "n_inventarios = len(zulianita_product_ids) * n_regiones * n_months\n",
    "\n",
    "inventarios = []\n",
    "inventario_id = 1\n",
    "\n",
    "current_date = end_date_data.replace(day=1)\n",
    "start_inventory_date = current_date - timedelta(days=365)\n",
    "inventory_dates = []\n",
    "\n",
    "while current_date > start_inventory_date:\n",
    "    last_day = (current_date.replace(month=current_date.month % 12 + 1, day=1) - timedelta(days=1)).date()\n",
    "    inventory_dates.append(last_day)\n",
    "    current_date = current_date.replace(month=current_date.month - 1 if current_date.month > 1 else 12, year=current_date.year - 1 if current_date.month == 1 else current_date.year)\n",
    "\n",
    "total_inventory_combinations = len(zulianita_product_ids) * n_regiones * len(inventory_dates)\n",
    "for fecha in inventory_dates:\n",
    "    for region_id in df_regiones['region_id']:\n",
    "        for producto_id in tqdm(zulianita_product_ids, desc=f\"Generando inventario para {fecha}\", leave=False, mininterval=1):\n",
    "            inventarios.append({\n",
    "                'inventario_id': inventario_id,\n",
    "                'producto_id': producto_id,\n",
    "                'region_id': region_id,\n",
    "                'stock': np.random.randint(50, 500),\n",
    "                'fecha_actualizacion': fecha\n",
    "            })\n",
    "            inventario_id += 1\n",
    "\n",
    "df_inventarios = pl.DataFrame(inventarios)\n",
    "\n",
    "# --- 8. Tabla Ventas ---\n",
    "sales_data_chunks = []\n",
    "venta_id_counter_final = 1\n",
    "\n",
    "last_product_monthly_state = {}\n",
    "monthly_product_target_quantities = {}\n",
    "daily_product_sales_distribution = {}\n",
    "\n",
    "product_category_map = {row['producto_id']: row['categoria'] for row in df_productos.select(['producto_id', 'categoria']).iter_rows(named=True)}\n",
    "product_brand_map = {row['producto_id']: row['marca'] for row in df_productos.select(['producto_id', 'marca']).iter_rows(named=True)}\n",
    "\n",
    "total_days_simulation = (end_date_data - start_date_data).days + 1\n",
    "\n",
    "daily_sales_schema = {\n",
    "    'venta_id': pl.Int64,\n",
    "    'fecha': pl.String,\n",
    "    'cliente_id': pl.Int64,\n",
    "    'producto_id': pl.Int64,\n",
    "    'cantidad': pl.Int64,\n",
    "    'canal_id': pl.Int64,\n",
    "    'region_id': pl.Int64,\n",
    "    'promocion_id': pl.Int64,\n",
    "    'historico_precio_id': pl.Int64\n",
    "}\n",
    "\n",
    "monthly_sales_trend_multiplier = 1.0\n",
    "last_month_year = None\n",
    "\n",
    "# Preómputo de Precios\n",
    "price_lookup = {}\n",
    "for prod_id in df_productos['producto_id'].to_list():\n",
    "    price_records = df_historico_precios.filter(pl.col('producto_id') == prod_id).sort('fecha_actualizacion')\n",
    "    price_lookup[prod_id] = price_records\n",
    "\n",
    "sales_generated = 0\n",
    "promoted_sales_count = 0\n",
    "total_sales_count = 0\n",
    "\n",
    "target_promotion_ratio = 0.30  # Start with 30% as a baseline, adjust dynamically\n",
    "min_promotion_ratio = 0.20\n",
    "max_promotion_ratio = 0.40\n",
    "\n",
    "# Cantidades iniciales de producto para contorl de fluctuaciones\n",
    "initial_avg_quantity = n_ventas / n_productos / total_days_simulation * 30  # Approx monthly average\n",
    "if marca == 'Zulianita' :\n",
    "    juice_initial_quantity = 700\n",
    "else: \n",
    "    juice_initial_quantity = 500\n",
    "\n",
    "for day_offset in tqdm(range(total_days_simulation), desc=\"Generando datos de ventas\", mininterval=1):\n",
    "    current_sale_date = start_date_data + timedelta(days=day_offset)\n",
    "    current_sale_date_str = current_sale_date.strftime('%Y-%m-%d')\n",
    "    current_month_str = current_sale_date.strftime('%Y-%m')\n",
    "\n",
    "    month = current_sale_date.month\n",
    "    year = current_sale_date.year\n",
    "\n",
    "    if current_month_str != last_month_year:\n",
    "        if last_month_year is not None:\n",
    "            prev_month_end = current_sale_date - timedelta(days=1)\n",
    "            prev_month_start = prev_month_end.replace(day=1)\n",
    "            prev_month_str_for_key = prev_month_start.strftime('%Y-%m')\n",
    "\n",
    "            df_prev_month_sales_list = []\n",
    "            for chunk_df in sales_data_chunks:\n",
    "                chunk_filtered = chunk_df.filter(\n",
    "                    (pl.col('fecha').str.strptime(pl.Date, '%Y-%m-%d') >= prev_month_start.date()) &\n",
    "                    (pl.col('fecha').str.strptime(pl.Date, '%Y-%m-%d') <= prev_month_end.date())\n",
    "                )\n",
    "                if not chunk_filtered.is_empty():\n",
    "                    df_prev_month_sales_list.append(chunk_filtered)\n",
    "\n",
    "            if df_prev_month_sales_list:\n",
    "                df_prev_month_sales_combined = pl.concat(df_prev_month_sales_list, how=\"vertical_relaxed\")\n",
    "\n",
    "                df_prev_month_sales_combined = df_prev_month_sales_combined.join(\n",
    "                    df_historico_precios.select(['historico_precio_id', 'precio_base']),\n",
    "                    on='historico_precio_id',\n",
    "                    how='left'\n",
    "                )\n",
    "\n",
    "                monthly_summary = df_prev_month_sales_combined.group_by('producto_id').agg(\n",
    "                    pl.sum('cantidad').alias('cantidad_total'),\n",
    "                    pl.mean('precio_base').alias('precio_promedio')\n",
    "                )\n",
    "\n",
    "                for row in monthly_summary.iter_rows(named=True):\n",
    "                    key = (row['producto_id'], prev_month_str_for_key)\n",
    "                    last_product_monthly_state[key] = {\n",
    "                        'precio': row['precio_promedio'],\n",
    "                        'cantidad': row['cantidad_total']\n",
    "                    }\n",
    "\n",
    "        monthly_product_target_quantities.clear()\n",
    "        daily_product_sales_distribution.clear()\n",
    "\n",
    "        days_in_current_month = (current_sale_date.replace(month=current_sale_date.month % 12 + 1, day=1) - timedelta(days=1)).day\n",
    "\n",
    "        for prod_id in df_productos['producto_id'].to_list():\n",
    "            prev_month_key = (prod_id, (current_sale_date - timedelta(days=current_sale_date.day)).replace(day=1).strftime('%Y-%m'))\n",
    "\n",
    "            prev_month_total_quantity = last_product_monthly_state.get(prev_month_key, {'cantidad': 0})['cantidad']\n",
    "            prev_month_avg_price = last_product_monthly_state.get(prev_month_key, {'precio': 0})['precio']\n",
    "\n",
    "            if prev_month_total_quantity == 0:\n",
    "                base_target_quantity = (n_ventas / n_productos / total_days_simulation) * days_in_current_month * 2\n",
    "                if product_category_map[prod_id] == 'Jugo':\n",
    "                    base_target_quantity = juice_initial_quantity  # Set initial juice quantity to 700\n",
    "            else:\n",
    "                base_target_quantity = max(prev_month_total_quantity, juice_initial_quantity * 0.75)  # Use max to prevent decline propagation\n",
    "\n",
    "            current_price_record = price_lookup[prod_id].filter(\n",
    "                pl.col('fecha_actualizacion').cast(pl.Date) <= current_sale_date.date()\n",
    "            ).sort('fecha_actualizacion', descending=True).head(1)\n",
    "\n",
    "            current_prod_price = current_price_record['precio_base'].item() if not current_price_record.is_empty() else 100\n",
    "\n",
    "            porcentaje_cambio_precio = 0\n",
    "            if prev_month_avg_price > 0:\n",
    "                porcentaje_cambio_precio = (current_prod_price - prev_month_avg_price) / prev_month_avg_price\n",
    "\n",
    "            categoria_producto = product_category_map.get(prod_id)\n",
    "            rango_epd = elasticidades_por_categoria.get(categoria_producto, {'min': -1.0, 'max': -2.0})\n",
    "            epd_objetivo = random.uniform(rango_epd['min'], rango_epd['max'])\n",
    "            \n",
    "            if random.random() < prob_elasticidad_positiva:\n",
    "                epd_objetivo = random.uniform(rango_elasticidad_positiva['min'], rango_elasticidad_positiva['max'])\n",
    "\n",
    "            # Cap elasticity impact to prevent excessive decline\n",
    "            epd_influenced_change = min(epd_objetivo * porcentaje_cambio_precio, 0.0)  # No negative effect beyond zero\n",
    "\n",
    "            promociones_activas = df_promociones.filter(\n",
    "                (pl.col('fecha_inicio').cast(pl.Date) <= current_sale_date.date()) &\n",
    "                (pl.col('fecha_fin').cast(pl.Date) >= current_sale_date.date())\n",
    "            )\n",
    "\n",
    "            if not promociones_activas.is_empty():\n",
    "                descuento_promedio = promociones_activas['descuento_porcentaje'].mean() / 100\n",
    "                promotion_boost = random.uniform(MIN_PROMOTION_BOOST, MAX_PROMOTION_BOOST)\n",
    "                epd_influenced_change = epd_influenced_change * PROMOTION_ELASTICITY_MULTIPLIER * (1 + descuento_promedio)\n",
    "                base_monthly_change_factor = promotion_boost\n",
    "            else:\n",
    "                base_monthly_change_factor = random.uniform(0.95, 1.05) * (1 + epd_influenced_change)\n",
    "\n",
    "            # Cap the negative impact of elasticity\n",
    "            clipped_base_change_factor = np.clip(\n",
    "                base_monthly_change_factor,\n",
    "                0.95,  # Increased minimum to 0.95\n",
    "                1 + MAX_PERCENT_CHANGE_PER_MONTH_PRODUCT_AGGREGATE\n",
    "            )\n",
    "\n",
    "            # Enhanced growth for juices\n",
    "            if categoria_producto == 'Jugo' and marca == 'Zulianita':\n",
    "                growth_factor = 1.10  # Increased to 15% monthly growth\n",
    "            elif categoria_producto == 'Gaseosa' and marca == 'Zulianita':\n",
    "                growth_factor = 1.15\n",
    "            elif categoria_producto == 'Bebida Energética' and marca == 'Coca-Loca':\n",
    "                growth_factor = 1.15\n",
    "            else:\n",
    "                growth_factor = 1.05  # 5% for other categories\n",
    "\n",
    "            current_seasonal_multiplier = seasonal_multipliers.get(month, 1.0)\n",
    "            \n",
    "            if categoria_producto in ['Agua', 'Gaseosa', 'Bebida de Té']:\n",
    "                if month in [6, 7, 8]:\n",
    "                    current_seasonal_multiplier *= 1.35\n",
    "            \n",
    "            if month == 12:\n",
    "                current_seasonal_multiplier *= 1.35\n",
    "\n",
    "            final_monthly_change_factor = clipped_base_change_factor * current_seasonal_multiplier * growth_factor\n",
    "\n",
    "            # Dynamic floor for juices\n",
    "            target_monthly_quantity = int(base_target_quantity * final_monthly_change_factor)\n",
    "            if categoria_producto == 'Jugo':\n",
    "                target_monthly_quantity = max(target_monthly_quantity, int(juice_initial_quantity * 0.85))  # Floor at 85% of 700 (595)\n",
    "            else:\n",
    "                target_monthly_quantity = max(target_monthly_quantity, int(initial_avg_quantity * 0.5))  # Floor at 50% for others\n",
    "\n",
    "            monthly_product_target_quantities[(prod_id, current_month_str)] = target_monthly_quantity\n",
    "\n",
    "        for prod_id, total_monthly_q in monthly_product_target_quantities.items():\n",
    "            if prod_id[1] != current_month_str:\n",
    "                continue\n",
    "\n",
    "            base_daily_q = total_monthly_q / days_in_current_month\n",
    "\n",
    "            for d_offset_in_month in range(days_in_current_month):\n",
    "                date_in_month = current_sale_date.replace(day=1) + timedelta(days=d_offset_in_month)\n",
    "                daily_q = base_daily_q * random.uniform(1 - DAILY_QUANTITY_FLUCTUATION_FACTOR, 1 + DAILY_QUANTITY_FLUCTUATION_FACTOR)\n",
    "                daily_product_sales_distribution[(prod_id[0], date_in_month.strftime('%Y-%m-%d'))] = max(1, int(daily_q))\n",
    "\n",
    "        last_month_year = current_month_str\n",
    "\n",
    "    base_sales_per_day = n_ventas / total_days_simulation\n",
    "    overall_daily_sales_num_multiplier = random.uniform(0.95, 1.05)\n",
    "    num_sales_today = int(base_sales_per_day * monthly_sales_trend_multiplier * overall_daily_sales_num_multiplier)\n",
    "    num_sales_today = max(1, num_sales_today)\n",
    "\n",
    "    daily_sales_data = []\n",
    "\n",
    "    # Use tuple keys consistent with daily_product_sales_distribution\n",
    "    current_day_product_targets = {\n",
    "        (prod_id, current_sale_date_str): daily_product_sales_distribution.get((prod_id, current_sale_date_str), 0)\n",
    "        for prod_id in df_productos['producto_id'].to_list()\n",
    "    }\n",
    "\n",
    "    # Use only prod_id for products_for_today_sales\n",
    "    products_for_today_sales = [\n",
    "        prod_id[0] for prod_id, target_q in current_day_product_targets.items() if target_q > 0\n",
    "    ]\n",
    "\n",
    "    channel_weights = get_channel_weights(current_sale_date)\n",
    "    canal_ids = df_canales['canal_id'].to_list()\n",
    "    canal_probs = [channel_weights[canal_name] for canal_name in df_canales['nombre_canal']]\n",
    "\n",
    "    # Dynamic adjustment of promotion probability\n",
    "    current_promotion_ratio = promoted_sales_count / total_sales_count if total_sales_count > 0 else 0.50\n",
    "    adjusted_promotion_prob = np.clip(target_promotion_ratio + (0.50 - current_promotion_ratio) * 0.1, min_promotion_ratio, max_promotion_ratio)\n",
    "\n",
    "    for _ in range(num_sales_today):\n",
    "        product_id = None\n",
    "        if products_for_today_sales:\n",
    "            # Extract quantities for the current day using prod_id\n",
    "            remaining_quantities = np.array([\n",
    "                current_day_product_targets[(p_id, current_sale_date_str)]\n",
    "                for p_id in products_for_today_sales\n",
    "            ])\n",
    "            if remaining_quantities.sum() > 0:\n",
    "                probabilities = remaining_quantities / remaining_quantities.sum()\n",
    "                product_id = np.random.choice(products_for_today_sales, p=probabilities)\n",
    "            else:\n",
    "                product_id = random.choice(df_productos['producto_id'].to_list())\n",
    "        else:\n",
    "            product_id = random.choice(df_productos['producto_id'].to_list())\n",
    "\n",
    "        cliente_id = np.random.choice(df_clientes['cliente_id'])\n",
    "        region_id = client_to_region_id[cliente_id]\n",
    "        canal_id = np.random.choice(canal_ids, p=canal_probs)\n",
    "\n",
    "        promociones_validas_hoy = df_promociones.filter(\n",
    "            (pl.col('fecha_inicio').cast(pl.Date) <= current_sale_date.date()) &\n",
    "            (pl.col('fecha_fin').cast(pl.Date) >= current_sale_date.date())\n",
    "        )\n",
    "\n",
    "        promocion_id = None\n",
    "        if not promociones_validas_hoy.is_empty() and random.random() < adjusted_promotion_prob:\n",
    "            promocion_id = random.choice(promociones_validas_hoy['promocion_id'].to_list())\n",
    "\n",
    "        precio_registro = price_lookup[product_id].filter(\n",
    "            (pl.col('fecha_actualizacion').cast(pl.Date) <= current_sale_date.date())\n",
    "        ).sort('fecha_actualizacion', descending=True).head(1)\n",
    "\n",
    "        if precio_registro.is_empty():\n",
    "            continue\n",
    "\n",
    "        historico_precio_id = precio_registro['historico_precio_id'].item()\n",
    "\n",
    "        quantity = random.randint(MIN_QUANTITY_PER_SALE, MAX_QUANTITY_PER_SALE)\n",
    "\n",
    "        if (product_id, current_sale_date_str) in current_day_product_targets and current_day_product_targets[(product_id, current_sale_date_str)] > 0:\n",
    "            quantity_for_sale_attempt = random.randint(MIN_QUANTITY_PER_SALE, MAX_QUANTITY_PER_SALE)\n",
    "            quantity = min(quantity_for_sale_attempt, current_day_product_targets[(product_id, current_sale_date_str)])\n",
    "            quantity = max(1, quantity)\n",
    "\n",
    "            current_day_product_targets[(product_id, current_sale_date_str)] -= quantity\n",
    "            if current_day_product_targets[(product_id, current_sale_date_str)] <= 0:\n",
    "                if product_id in products_for_today_sales:\n",
    "                    products_for_today_sales.remove(product_id)\n",
    "\n",
    "        daily_sales_data.append({\n",
    "            'venta_id': venta_id_counter_final,\n",
    "            'fecha': current_sale_date_str,\n",
    "            'cliente_id': cliente_id,\n",
    "            'producto_id': product_id,\n",
    "            'cantidad': quantity,\n",
    "            'canal_id': canal_id,\n",
    "            'region_id': region_id,\n",
    "            'promocion_id': promocion_id,\n",
    "            'historico_precio_id': historico_precio_id\n",
    "        })\n",
    "        venta_id_counter_final += 1\n",
    "        total_sales_count += 1\n",
    "        if promocion_id is not None:\n",
    "            promoted_sales_count += 1\n",
    "\n",
    "        if venta_id_counter_final > n_ventas:\n",
    "            print(f\"Objetivo de {n_ventas} ventas alcanzado. Deteniendo la generación de datos.\")\n",
    "            break\n",
    "\n",
    "    if daily_sales_data:\n",
    "        sales_data_chunks.append(pl.DataFrame(daily_sales_data, schema=daily_sales_schema))\n",
    "    \n",
    "    if venta_id_counter_final > n_ventas:\n",
    "        break\n",
    "\n",
    "\n",
    "df_ventas = pl.concat([chunk for chunk in tqdm(sales_data_chunks, desc=\"Concatenando ventas\", mininterval=1)], how=\"vertical_relaxed\")\n",
    "df_ventas = df_ventas.slice(0, n_ventas)\n",
    "\n",
    "# --- Guardar en CSV ---\n",
    "df_clientes.write_csv('clientes.csv')\n",
    "df_productos.write_csv('productos.csv')\n",
    "df_historico_precios.write_csv('historico_precios.csv')\n",
    "df_canales.write_csv('canales.csv')\n",
    "df_regiones.write_csv('regiones.csv')\n",
    "df_promociones.write_csv('promociones.csv')\n",
    "df_inventarios.write_csv('inventarios.csv')\n",
    "df_ventas.write_csv('ventas.csv')\n",
    "\n",
    "print(f\"\\nConjuntos de datos generados y guardados como CSV.\")\n",
    "print(f\"Total de ventas: {len(df_ventas)}\")\n",
    "print(f\"Total de productos: {len(df_productos)}\")\n",
    "print(f\"Total de entradas de historial de precios: {len(df_historico_precios)}\")\n",
    "print(f\"Total de clientes: {len(df_clientes)}\")\n",
    "print(f\"Total de regiones: {len(df_regiones)}\")\n",
    "print(f\"Total de canales: {len(df_canales)}\")\n",
    "print(f\"Total de promociones: {len(df_promociones)}\")\n",
    "print(f\"Total de entradas de inventario: {len(df_inventarios)}\")\n",
    "\n",
    "# --- Verificación de distribución de regiones en clientes ---\n",
    "print(\"\\nDistribución de regiones en clientes:\")\n",
    "region_dist = df_clientes.group_by('ciudad').agg(pl.count('cliente_id').alias('num_clientes')).sort('num_clientes', descending=True)\n",
    "for row in region_dist.iter_rows(named=True):\n",
    "    print(f\"{row['ciudad']}: {row['num_clientes']} clientes ({row['num_clientes']/n_clientes*100:.2f}%)\")\n",
    "\n",
    "# --- Verificación de consistencia de region_id en ventas ---\n",
    "print(\"\\nVerificación de consistencia de region_id en ventas:\")\n",
    "sample_ventas = df_ventas.join(df_clientes.select(['cliente_id', 'region_id']), on='cliente_id', how='left').head(5)\n",
    "for row in sample_ventas.iter_rows(named=True):\n",
    "    print(f\"Venta ID {row['venta_id']}: Cliente ID {row['cliente_id']}, Venta region_id {row['region_id']}, Cliente region_id {row['region_id_right']}\")\n",
    "\n",
    "# --- Verificación de competidores por categoría ---\n",
    "print(\"\\nVerificación de competidores por categoría:\")\n",
    "competitor_dist = df_productos.filter(pl.col('marca') != 'Zulianita').group_by('categoria', 'marca').agg(pl.count('producto_id').alias('num_productos')).sort('categoria')\n",
    "for row in competitor_dist.iter_rows(named=True):\n",
    "    print(f\"Categoría {row['categoria']}, Marca {row['marca']}: {row['num_productos']} productos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
