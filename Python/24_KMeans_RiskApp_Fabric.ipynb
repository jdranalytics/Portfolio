{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb64072",
   "metadata": {},
   "source": [
    "## MODELO DE CLUSTERIZACIÓN DE SOLICITUDES DE CRÉDITO (K-MEANS) PARA RIESGO DE CRÉDITO\n",
    "\n",
    "#### NOTEBOOK: Clustering_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb0860",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.sql.functions import col, when, count, isnan, isnull, lit\n",
    "from pyspark.sql.types import StructType, StructField, TimestampType, IntegerType, DoubleType, BooleanType\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear o obtener la sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ClusteringModel\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Sesión de Spark activa:\", spark)\n",
    "\n",
    "# Cargar datos con manejo de errores\n",
    "try:\n",
    "    df = spark.read.format(\"delta\").load(\"Tables/solicitudes_processed\")\n",
    "    print(f\"Datos cargados exitosamente. Total de registros: {df.count()}\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error al cargar los datos: {str(e)}\")\n",
    "\n",
    "# Definir columnas de entrada\n",
    "input_cols = [\"edad\", \"ingresos_anuales\", \"puntaje_crediticio\", \"deuda_actual\",\n",
    "              \"antiguedad_laboral\", \"historial_pagos_encoded\", \"estado_civil_encoded\",\n",
    "              \"tipo_empleo_encoded\", \"numero_dependientes\"]\n",
    "\n",
    "# Análisis de valores nulos antes de la limpieza\n",
    "print(\"\\nAnálisis de valores nulos antes de la limpieza:\")\n",
    "for column in input_cols:\n",
    "    null_count = df.filter(col(column).isNull() | isnan(col(column))).count()\n",
    "    total = df.count()\n",
    "    null_percentage = (null_count / total) * 100\n",
    "    print(f\"{column}: {null_count} nulos ({null_percentage:.2f}%)\")\n",
    "\n",
    "# Manejar valores nulos con estrategia más sofisticada\n",
    "for col_name in input_cols:\n",
    "    # Usar la mediana para variables numéricas\n",
    "    if col_name in [\"edad\", \"ingresos_anuales\", \"puntaje_crediticio\", \"deuda_actual\", \"antiguedad_laboral\"]:\n",
    "        median_value = df.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "        df = df.fillna(median_value, subset=[col_name])\n",
    "    else:\n",
    "        # Usar 0 para variables categóricas codificadas\n",
    "        df = df.fillna(0, subset=[col_name])\n",
    "\n",
    "# Verificar que no queden nulos\n",
    "null_check = df.select([count(when(col(c).isNull() | isnan(col(c)), c)).alias(c) for c in input_cols])\n",
    "print(\"\\nVerificación final de valores nulos:\")\n",
    "null_check.show()\n",
    "\n",
    "# Dividir datos aleatoriamente para evitar sesgos\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=123)\n",
    "print(f\"Datos de entrenamiento: {train_df.count()} registros\")\n",
    "print(f\"Datos de prueba: {test_df.count()} registros\")\n",
    "\n",
    "# Preparar características\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=input_cols,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"  # Manejo explícito de valores inválidos\n",
    ")\n",
    "\n",
    "# Transformar datos\n",
    "features_df = assembler.transform(train_df).select(\"features\")\n",
    "\n",
    "# Método del codo para determinar k óptimo\n",
    "print(\"Ejecutando método del codo...\")\n",
    "elbow_results = []\n",
    "k_range = range(2, 11)  # Probar k de 2 a 10\n",
    "\n",
    "try:\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(\n",
    "            featuresCol=\"features\",\n",
    "            predictionCol=\"prediction\",\n",
    "            k=k,\n",
    "            seed=123\n",
    "        )\n",
    "        model = kmeans.fit(features_df)\n",
    "        cost = model.summary.trainingCost  # WSS\n",
    "        elbow_results.append((k, cost))\n",
    "        print(f\"k={k}, Costo (WSS): {cost:.4f}\")\n",
    "\n",
    "    # Seleccionar k óptimo (heurística: menor disminución relativa en costo)\n",
    "    cost_changes = [(k, elbow_results[i][1] / elbow_results[i-1][1]) for i, (k, _) in enumerate(elbow_results[1:], 1)]\n",
    "    optimal_k = min(cost_changes, key=lambda x: x[1])[0] if cost_changes else 4\n",
    "    print(f\"\\nNúmero óptimo de clústeres (k): {optimal_k}\")\n",
    "\n",
    "    # Crear DataFrame para resultados del método del codo con la nueva columna\n",
    "    elbow_schema = StructType([\n",
    "        StructField(\"fecha_entrenamiento\", TimestampType(), False),\n",
    "        StructField(\"k\", IntegerType(), False),\n",
    "        StructField(\"costo\", DoubleType(), False),\n",
    "        StructField(\"es_mejor_modelo\", BooleanType(), False)\n",
    "    ])\n",
    "\n",
    "    # Preparar datos con la marca del mejor modelo\n",
    "    current_time = datetime.now()\n",
    "    elbow_data = [(\n",
    "        current_time,\n",
    "        k,\n",
    "        float(cost),\n",
    "        k == optimal_k  # True solo para el k óptimo\n",
    "    ) for k, cost in elbow_results]\n",
    "\n",
    "    elbow_df = spark.createDataFrame(elbow_data, schema=elbow_schema)\n",
    "\n",
    "    # Guardar resultados del método del codo\n",
    "    try:\n",
    "        elbow_df.write.mode(\"append\").format(\"delta\").save(\"Tables/elbow_method_results\")\n",
    "        print(\"Resultados del método del codo guardados exitosamente\")\n",
    "        print(f\"Se marcó k={optimal_k} como el mejor modelo\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar resultados del método del codo: {e}\")\n",
    "        raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante el método del codo: {e}\")\n",
    "    raise\n",
    "\n",
    "# Entrenar modelo K-means final\n",
    "kmeans = KMeans(\n",
    "    featuresCol=\"features\",\n",
    "    predictionCol=\"prediction\",\n",
    "    k=optimal_k,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"Iniciando entrenamiento del modelo K-means final...\")\n",
    "    kmeans_model = kmeans.fit(features_df)\n",
    "    print(\"Modelo K-means entrenado exitosamente\")\n",
    "\n",
    "    # Evaluar modelo con datos de prueba\n",
    "    test_features = assembler.transform(test_df).select(\"features\")\n",
    "    predictions = kmeans_model.transform(test_features)\n",
    "    evaluator = ClusteringEvaluator(\n",
    "        predictionCol=\"prediction\",\n",
    "        featuresCol=\"features\",\n",
    "        metricName=\"silhouette\",\n",
    "        distanceMeasure=\"squaredEuclidean\"\n",
    "    )\n",
    "    silhouette_score = evaluator.evaluate(predictions)\n",
    "    print(f\"\\nPuntaje de silueta: {silhouette_score:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error durante el entrenamiento o evaluación: {str(e)}\")\n",
    "\n",
    "# Guardar modelo K-means\n",
    "lakehouse_id = \"a2c9f91b-6c69-4d1d-96f9-24b310914c2b\"\n",
    "model_path = f\"Tables/Models/KMeansClustering\"\n",
    "\n",
    "try:\n",
    "    print(f\"\\nGuardando modelo en: {model_path}\")\n",
    "    kmeans_model.write().overwrite().save(model_path)\n",
    "    print(f\"Modelo K-means guardado exitosamente en {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el modelo: {e}\")\n",
    "    # Intentar ruta alternativa\n",
    "    try:\n",
    "        alt_path = \"./models/KMeansClustering\"\n",
    "        print(f\"Intentando guardar en ruta alternativa: {alt_path}\")\n",
    "        kmeans_model.write().overwrite().save(alt_path)\n",
    "        print(f\"Modelo guardado en ruta alternativa: {alt_path}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error al guardar en ruta alternativa: {e2}\")\n",
    "        raise\n",
    "\n",
    "# Registrar métricas\n",
    "metrics_schema = StructType([\n",
    "    StructField(\"fecha_entrenamiento\", TimestampType(), False),\n",
    "    StructField(\"k\", IntegerType(), False),\n",
    "    StructField(\"silhouette_score\", DoubleType(), False),\n",
    "    StructField(\"costo_final\", DoubleType(), False)\n",
    "])\n",
    "\n",
    "metrics_df = spark.createDataFrame([(\n",
    "    datetime.now(),\n",
    "    optimal_k,\n",
    "    float(silhouette_score),\n",
    "    float(kmeans_model.summary.trainingCost)\n",
    ")], schema=metrics_schema)\n",
    "\n",
    "try:\n",
    "    metrics_df.write.mode(\"append\").format(\"delta\").save(\"Tables/kmeans_metrics\")\n",
    "    print(\"\\nMétricas guardadas exitosamente\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar métricas: {e}\")\n",
    "    raise\n",
    "\n",
    "# Notificar resultados a Discord\n",
    "discord_webhook_url = os.getenv('DISCORD_WEBHOOK_URL', \"XXXXXXXXXXXXX\")\n",
    "\n",
    "def crear_mensaje_exito(silhouette, k, costo):\n",
    "    return {\n",
    "        \"embeds\": [\n",
    "            {\n",
    "                \"title\": \"✅ Reentrenamiento Exitoso - K-means Clustering\",\n",
    "                \"description\": \"El modelo de clustering ha sido reentrenado exitosamente.\",\n",
    "                \"color\": 3066993,  # Verde\n",
    "                \"fields\": [\n",
    "                    {\"name\": \"Número de clústeres (k)\", \"value\": str(k), \"inline\": True},\n",
    "                    {\"name\": \"Puntaje de silueta\", \"value\": f\"{silhouette:.4f}\", \"inline\": True},\n",
    "                    {\"name\": \"Costo final\", \"value\": f\"{costo:.4f}\", \"inline\": True}\n",
    "                ],\n",
    "                \"footer\": {\"text\": \"RiskApp - Sistema de Monitoreo\"},\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def crear_mensaje_error(error):\n",
    "    return {\n",
    "        \"embeds\": [\n",
    "            {\n",
    "                \"title\": \"❌ Error en el Reentrenamiento - K-means Clustering\",\n",
    "                \"description\": f\"Se produjo un error durante el reentrenamiento: {error}\",\n",
    "                \"color\": 15158332,  # Rojo\n",
    "                \"footer\": {\"text\": \"RiskApp - Sistema de Monitoreo\"},\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def enviar_notificacion(mensaje):\n",
    "    try:\n",
    "        response = requests.post(discord_webhook_url, json=mensaje)\n",
    "        response.raise_for_status()\n",
    "        print(\"\\nNotificación enviada exitosamente a Discord\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al enviar notificación: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    mensaje = crear_mensaje_exito(\n",
    "        silhouette=silhouette_score,\n",
    "        k=optimal_k,\n",
    "        costo=kmeans_model.summary.trainingCost\n",
    "    )\n",
    "    enviar_notificacion(mensaje)\n",
    "except Exception as e:\n",
    "    mensaje = crear_mensaje_error(str(e))\n",
    "    enviar_notificacion(mensaje)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
