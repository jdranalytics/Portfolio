{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51244f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando datos de ventas: 100%|██████████| 897/897 [08:26<00:00,  1.77it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjuntos de datos generados y guardados como CSV.\n",
      "Total de ventas: 199330\n",
      "Total de productos: 40\n",
      "Total de entradas de historial de precios: 1200\n",
      "Total de clientes: 2000\n",
      "Total de regiones: 10\n",
      "Total de canales: 5\n",
      "Total de promociones: 20\n",
      "Total de entradas de inventario: 120\n",
      "\n",
      "Verificación de variación mensual (primeros 5 productos):\n",
      "Producto 1:\n",
      "  2023-1 a 2023-2: -9.85%\n",
      "  2023-2 a 2023-3: 17.27%\n",
      "  2023-3 a 2023-4: 1.60%\n",
      "  2023-4 a 2023-5: -3.70%\n",
      "  2023-5 a 2023-6: 0.72%\n",
      "  2023-6 a 2023-7: -17.13%\n",
      "  2023-7 a 2023-8: -13.19%\n",
      "  2023-8 a 2023-9: -4.10%\n",
      "  2023-9 a 2023-10: 2.95%\n",
      "  2023-10 a 2023-11: -2.29%\n",
      "  2023-11 a 2023-12: 28.06%\n",
      "  2023-12 a 2024-1: -20.25%\n",
      "  2024-1 a 2024-2: 3.08%\n",
      "  2024-2 a 2024-3: 22.55%\n",
      "  2024-3 a 2024-4: 0.62%\n",
      "  2024-4 a 2024-5: -1.41%\n",
      "  2024-5 a 2024-6: -16.37%\n",
      "  2024-6 a 2024-7: 3.22%\n",
      "  2024-7 a 2024-8: -17.04%\n",
      "  2024-8 a 2024-9: -17.27%\n",
      "  2024-9 a 2024-10: 19.81%\n",
      "  2024-10 a 2024-11: 5.08%\n",
      "  2024-11 a 2024-12: 34.77%\n",
      "  2024-12 a 2025-1: -3.42%\n",
      "  2025-1 a 2025-2: -13.68%\n",
      "  2025-2 a 2025-3: 10.45%\n",
      "  2025-3 a 2025-4: -3.53%\n",
      "  2025-4 a 2025-5: 1.79%\n",
      "  2025-5 a 2025-6: -53.02%\n",
      "Producto 2:\n",
      "  2023-1 a 2023-2: 3.27%\n",
      "  2023-2 a 2023-3: 3.71%\n",
      "  2023-3 a 2023-4: 3.20%\n",
      "  2023-4 a 2023-5: 6.61%\n",
      "  2023-5 a 2023-6: 21.94%\n",
      "  2023-6 a 2023-7: 18.07%\n",
      "  2023-7 a 2023-8: 8.67%\n",
      "  2023-8 a 2023-9: -4.93%\n",
      "  2023-9 a 2023-10: -5.04%\n",
      "  2023-10 a 2023-11: -3.32%\n",
      "  2023-11 a 2023-12: 20.01%\n",
      "  2023-12 a 2024-1: -15.40%\n",
      "  2024-1 a 2024-2: -14.26%\n",
      "  2024-2 a 2024-3: -4.41%\n",
      "  2024-3 a 2024-4: -2.82%\n",
      "  2024-4 a 2024-5: 6.52%\n",
      "  2024-5 a 2024-6: 20.21%\n",
      "  2024-6 a 2024-7: 10.15%\n",
      "  2024-7 a 2024-8: 6.99%\n",
      "  2024-8 a 2024-9: -6.01%\n",
      "  2024-9 a 2024-10: -11.16%\n",
      "  2024-10 a 2024-11: -7.95%\n",
      "  2024-11 a 2024-12: 21.81%\n",
      "  2024-12 a 2025-1: -9.62%\n",
      "  2025-1 a 2025-2: -13.38%\n",
      "  2025-2 a 2025-3: -0.50%\n",
      "  2025-3 a 2025-4: 2.71%\n",
      "  2025-4 a 2025-5: -1.70%\n",
      "  2025-5 a 2025-6: -38.03%\n",
      "Producto 3:\n",
      "  2023-1 a 2023-2: -0.37%\n",
      "  2023-2 a 2023-3: 16.68%\n",
      "  2023-3 a 2023-4: -9.79%\n",
      "  2023-4 a 2023-5: 2.65%\n",
      "  2023-5 a 2023-6: 6.55%\n",
      "  2023-6 a 2023-7: -21.30%\n",
      "  2023-7 a 2023-8: -20.72%\n",
      "  2023-8 a 2023-9: -11.80%\n",
      "  2023-9 a 2023-10: 7.20%\n",
      "  2023-10 a 2023-11: -6.64%\n",
      "  2023-11 a 2023-12: 14.89%\n",
      "  2023-12 a 2024-1: -14.80%\n",
      "  2024-1 a 2024-2: -1.47%\n",
      "  2024-2 a 2024-3: 30.79%\n",
      "  2024-3 a 2024-4: -2.21%\n",
      "  2024-4 a 2024-5: 7.27%\n",
      "  2024-5 a 2024-6: -2.81%\n",
      "  2024-6 a 2024-7: -15.07%\n",
      "  2024-7 a 2024-8: -9.99%\n",
      "  2024-8 a 2024-9: -18.33%\n",
      "  2024-9 a 2024-10: 13.49%\n",
      "  2024-10 a 2024-11: -2.14%\n",
      "  2024-11 a 2024-12: 5.79%\n",
      "  2024-12 a 2025-1: -6.82%\n",
      "  2025-1 a 2025-2: -3.18%\n",
      "  2025-2 a 2025-3: 35.19%\n",
      "  2025-3 a 2025-4: 0.29%\n",
      "  2025-4 a 2025-5: 6.74%\n",
      "  2025-5 a 2025-6: -52.47%\n",
      "Producto 4:\n",
      "  2023-1 a 2023-2: -8.13%\n",
      "  2023-2 a 2023-3: 20.10%\n",
      "  2023-3 a 2023-4: 7.16%\n",
      "  2023-4 a 2023-5: 7.98%\n",
      "  2023-5 a 2023-6: 22.29%\n",
      "  2023-6 a 2023-7: 16.31%\n",
      "  2023-7 a 2023-8: 6.44%\n",
      "  2023-8 a 2023-9: -3.77%\n",
      "  2023-9 a 2023-10: -3.37%\n",
      "  2023-10 a 2023-11: -2.86%\n",
      "  2023-11 a 2023-12: 16.49%\n",
      "  2023-12 a 2024-1: -9.72%\n",
      "  2024-1 a 2024-2: -9.59%\n",
      "  2024-2 a 2024-3: 2.01%\n",
      "  2024-3 a 2024-4: -1.87%\n",
      "  2024-4 a 2024-5: 5.88%\n",
      "  2024-5 a 2024-6: 10.78%\n",
      "  2024-6 a 2024-7: 11.94%\n",
      "  2024-7 a 2024-8: 5.67%\n",
      "  2024-8 a 2024-9: -7.54%\n",
      "  2024-9 a 2024-10: -8.37%\n",
      "  2024-10 a 2024-11: -4.16%\n",
      "  2024-11 a 2024-12: 19.52%\n",
      "  2024-12 a 2025-1: -15.65%\n",
      "  2025-1 a 2025-2: -14.75%\n",
      "  2025-2 a 2025-3: 5.16%\n",
      "  2025-3 a 2025-4: -11.92%\n",
      "  2025-4 a 2025-5: 0.30%\n",
      "  2025-5 a 2025-6: -40.31%\n",
      "Producto 5:\n",
      "  2023-1 a 2023-2: -4.97%\n",
      "  2023-2 a 2023-3: 8.18%\n",
      "  2023-3 a 2023-4: 2.90%\n",
      "  2023-4 a 2023-5: 12.10%\n",
      "  2023-5 a 2023-6: 9.31%\n",
      "  2023-6 a 2023-7: -0.77%\n",
      "  2023-7 a 2023-8: 4.18%\n",
      "  2023-8 a 2023-9: -11.38%\n",
      "  2023-9 a 2023-10: -13.48%\n",
      "  2023-10 a 2023-11: -3.92%\n",
      "  2023-11 a 2023-12: 23.09%\n",
      "  2023-12 a 2024-1: -8.08%\n",
      "  2024-1 a 2024-2: -7.01%\n",
      "  2024-2 a 2024-3: 7.99%\n",
      "  2024-3 a 2024-4: -8.18%\n",
      "  2024-4 a 2024-5: -0.91%\n",
      "  2024-5 a 2024-6: 26.75%\n",
      "  2024-6 a 2024-7: 19.52%\n",
      "  2024-7 a 2024-8: -2.27%\n",
      "  2024-8 a 2024-9: -12.61%\n",
      "  2024-9 a 2024-10: -4.83%\n",
      "  2024-10 a 2024-11: 2.56%\n",
      "  2024-11 a 2024-12: 13.47%\n",
      "  2024-12 a 2025-1: -14.79%\n",
      "  2025-1 a 2025-2: -15.34%\n",
      "  2025-2 a 2025-3: 20.72%\n",
      "  2025-3 a 2025-4: -6.79%\n",
      "  2025-4 a 2025-5: -0.20%\n",
      "  2025-5 a 2025-6: -44.75%\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Init Faker\n",
    "fake = Faker('es_CO')\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# --- Parameters ---\n",
    "n_ventas = 200000\n",
    "n_clientes = 2000\n",
    "n_productos = 40\n",
    "n_canales = 5\n",
    "n_promociones = 20\n",
    "n_regiones = 10\n",
    "n_inventarios = 120\n",
    "\n",
    "start_date_data = datetime(2023, 1, 1)\n",
    "end_date_data = datetime(2025, 6, 15)\n",
    "\n",
    "# Elasticity parameters - Ajustados para mayor sensibilidad al precio\n",
    "elasticidades_por_categoria = {\n",
    "    'Agua': {'min': -0.8, 'max': -1.2},           # Más sensible al precio\n",
    "    'Gaseosa': {'min': -1.0, 'max': -1.5},        # Más sensible al precio\n",
    "    'Jugo': {'min': -1.2, 'max': -1.8},           # Más sensible al precio\n",
    "    'Bebida de Té': {'min': -1.5, 'max': -2.2},   # Más sensible al precio\n",
    "    'Bebida Energética': {'min': -2.0, 'max': -3.0}  # Muy sensible al precio\n",
    "}\n",
    "# Reducida la probabilidad de elasticidad positiva para casos excepcionales\n",
    "prob_elasticidad_positiva = 0.01\n",
    "rango_elasticidad_positiva = {'min': 0.05, 'max': 0.2}\n",
    "\n",
    "# --- NUEVOS PARÁMETROS DE CONTROL DE FLUCTUACIÓN POR PRODUCTO (AJUSTADOS) ---\n",
    "MAX_PERCENT_CHANGE_PER_MONTH_PRODUCT_AGGREGATE = 0.12  # Aumentado para permitir más variación\n",
    "MIN_QUANTITY_PER_SALE = 1\n",
    "MAX_QUANTITY_PER_SALE = 24\n",
    "DAILY_QUANTITY_FLUCTUATION_FACTOR = 0.25  # Aumentado para más variación diaria\n",
    "\n",
    "# --- SEASONALITY ADJUSTMENT - Reforzado para meses cálidos y diciembre ---\n",
    "seasonal_multipliers = {\n",
    "    1: random.uniform(0.85, 0.90),   # Jan (Post-holiday drop)\n",
    "    2: random.uniform(0.80, 0.85),   # Feb (Low season)\n",
    "    3: random.uniform(0.85, 0.90),   # Mar\n",
    "    4: random.uniform(0.90, 0.95),   # Apr\n",
    "    5: random.uniform(0.95, 1.0),    # May (Preparing for summer)\n",
    "    6: random.uniform(1.25, 1.35),   # Jun (Strong summer season start)\n",
    "    7: random.uniform(1.35, 1.45),   # Jul (Peak summer season)\n",
    "    8: random.uniform(1.30, 1.40),   # Aug (Strong summer season)\n",
    "    9: random.uniform(0.95, 1.0),    # Sep (Post-summer normalization)\n",
    "    10: random.uniform(0.85, 0.90),  # Oct\n",
    "    11: random.uniform(0.95, 1.0),   # Nov (Preparing for holidays)\n",
    "    12: random.uniform(1.35, 1.45)   # Dec (Strong holiday season)\n",
    "}\n",
    "\n",
    "# --- PROMOTIONAL IMPACT PARAMETERS (NUEVOS) ---\n",
    "PROMOTION_ELASTICITY_MULTIPLIER = 1.5  # Multiplicador del efecto de elasticidad durante promociones\n",
    "MIN_PROMOTION_BOOST = 1.2  # Mínimo impulso a las ventas durante promociones\n",
    "MAX_PROMOTION_BOOST = 1.8  # Máximo impulso a las ventas durante promociones\n",
    "\n",
    "# --- 1. Regions Table ---\n",
    "ciudades_colombia = [\n",
    "    {\"nombre_region\": \"Cundinamarca\", \"ciudad\": \"Bogotá\", \"latitud\": 4.7110, \"longitud\": -74.0721},\n",
    "    {\"nombre_region\": \"Antioquia\", \"ciudad\": \"Medellín\", \"latitud\": 6.2442, \"longitud\": -75.5812},\n",
    "    {\"nombre_region\": \"Valle del Cauca\", \"ciudad\": \"Cali\", \"latitud\": 3.4516, \"longitud\": -76.5320},\n",
    "    {\"nombre_region\": \"Atlántico\", \"ciudad\": \"Barranquilla\", \"latitud\": 10.9685, \"longitud\": -74.7813},\n",
    "    {\"nombre_region\": \"Bolívar\", \"ciudad\": \"Cartagena\", \"latitud\": 10.3910, \"longitud\": -75.4794},\n",
    "    {\"nombre_region\": \"Santander\", \"ciudad\": \"Bucaramanga\", \"latitud\": 7.1254, \"longitud\": -73.1198},\n",
    "    {\"nombre_region\": \"Norte de Santander\", \"ciudad\": \"Cúcuta\", \"latitud\": 7.8939, \"longitud\": -72.5078},\n",
    "    {\"nombre_region\": \"Tolima\", \"ciudad\": \"Ibagué\", \"latitud\": 4.4389, \"longitud\": -75.2114},\n",
    "    {\"nombre_region\": \"Meta\", \"ciudad\": \"Villavicencio\", \"latitud\": 4.1415, \"longitud\": -73.6268},\n",
    "    {\"nombre_region\": \"Boyacá\", \"ciudad\": \"Tunja\", \"latitud\": 5.5352, \"longitud\": -73.3677}\n",
    "]\n",
    "\n",
    "regiones_data = []\n",
    "for i in range(n_regiones):\n",
    "    region_info = ciudades_colombia[i] if i < len(ciudades_colombia) else random.choice(ciudades_colombia)\n",
    "    regiones_data.append({\n",
    "        'region_id': i + 1,\n",
    "        'nombre_region': region_info['nombre_region'],\n",
    "        'ciudad': region_info['ciudad'],\n",
    "        'latitud': region_info['latitud'],\n",
    "        'longitud': region_info['longitud']\n",
    "    })\n",
    "df_regiones = pl.DataFrame(regiones_data)\n",
    "\n",
    "# Region weights\n",
    "pesos_regiones = {\n",
    "    \"Bogotá\": 0.25, \"Medellín\": 0.20, \"Cali\": 0.15, \"Barranquilla\": 0.15,\n",
    "    \"Cartagena\": 0.10, \"Bucaramanga\": 0.05, \"Cúcuta\": 0.04,\n",
    "    \"Ibagué\": 0.03, \"Villavicencio\": 0.02, \"Tunja\": 0.01\n",
    "}\n",
    "prob_regiones_para_seleccion = np.array([pesos_regiones.get(row['ciudad'], 0.01) for row in df_regiones.iter_rows(named=True)])\n",
    "prob_regiones_para_seleccion /= prob_regiones_para_seleccion.sum()\n",
    "regiones_para_seleccion = df_regiones['region_id'].to_list()\n",
    "\n",
    "# --- 2. Clients Table ---\n",
    "ciudades_regiones = df_regiones['ciudad'].to_list()\n",
    "\n",
    "# Calcular fechas límite para la distribución de última compra\n",
    "fecha_actual = end_date_data\n",
    "fecha_365_dias_atras = fecha_actual - timedelta(days=365)\n",
    "\n",
    "# Determinar el número exacto de clientes inactivos (entre 5% y 15%)\n",
    "porcentaje_inactivos = random.uniform(0.05, 0.15)\n",
    "n_clientes_inactivos = int(n_clientes * porcentaje_inactivos)\n",
    "n_clientes_activos = n_clientes - n_clientes_inactivos\n",
    "\n",
    "clientes = []\n",
    "for i in range(1, n_clientes + 1):\n",
    "    # Determinar si este cliente será inactivo\n",
    "    es_inactivo = i <= n_clientes_inactivos\n",
    "    \n",
    "    if es_inactivo:\n",
    "        # Para clientes inactivos, última compra entre 365 y 730 días atrás\n",
    "        ultima_compra = fake.date_between(\n",
    "            start_date=fecha_actual - timedelta(days=730),\n",
    "            end_date=fecha_365_dias_atras\n",
    "        )\n",
    "    else:\n",
    "        # Para clientes activos, última compra en los últimos 365 días\n",
    "        ultima_compra = fake.date_between(\n",
    "            start_date=fecha_365_dias_atras,\n",
    "            end_date=fecha_actual\n",
    "        )\n",
    "    \n",
    "    clientes.append({\n",
    "        'cliente_id': i,\n",
    "        'nombre': fake.name(),\n",
    "        'edad': np.random.randint(18, 80),\n",
    "        'genero': np.random.choice(['M', 'F']),\n",
    "        'ciudad': random.choice(ciudades_regiones),\n",
    "        'frecuencia_compra': np.random.randint(1, 20),\n",
    "        'ultima_compra': ultima_compra\n",
    "    })\n",
    "df_clientes = pl.DataFrame(clientes)\n",
    "\n",
    "# --- 3. Products Table ---\n",
    "volumenes_gaseosa_jugo_ml = [250, 600, 1000, 2000]\n",
    "unidades_por_caja_gaseosa_jugo = [6, 12, 24]\n",
    "volumenes_energia_ml = [250, 500]\n",
    "unidades_por_caja_energia = [4, 6]\n",
    "volumenes_agua_ml = [500, 1000, 2000, 5000]\n",
    "unidades_por_caja_agua = [1, 6, 12]\n",
    "\n",
    "categorias_marcas_sabor_base = [\n",
    "    {'categoria_base': 'Gaseosa', 'sabores': ['Cola', 'Naranja', 'Limón', 'Piña', 'Manzanita', 'Uva'], 'marcas': ['Zulianita', 'Competidor1']},\n",
    "    {'categoria_base': 'Bebida de Té', 'sabores': ['Té Negro', 'Té Verde'], 'marcas': ['Zulianita', 'Competidor2']},\n",
    "    {'categoria_base': 'Jugo', 'sabores': ['Jugo Naranja', 'Jugo Manzana', 'Jugo Lima'], 'marcas': ['Zulianita', 'Competidor1']},\n",
    "    {'categoria_base': 'Bebida Energética', 'sabores': ['Energía Extrema', 'Power Up'], 'marcas': ['Zulianita', 'Competidor2']},\n",
    "    {'categoria_base': 'Agua', 'sabores': ['Agua con Gas', 'Agua Sin Gas'], 'marcas': ['Zulianita', 'Competidor1']}\n",
    "]\n",
    "\n",
    "productos = []\n",
    "for i in range(n_productos):\n",
    "    tipo_prod_info = random.choice(categorias_marcas_sabor_base)\n",
    "    categoria = tipo_prod_info['categoria_base']\n",
    "    sabor = random.choice(tipo_prod_info['sabores'])\n",
    "    marca = random.choice(tipo_prod_info['marcas'])\n",
    "\n",
    "    nombre_producto_str = sabor\n",
    "    volumen_ml_val = 0\n",
    "    unidades_caja_val = 1\n",
    "\n",
    "    if categoria in ['Gaseosa', 'Jugo']:\n",
    "        volumen_ml_val = random.choice(volumenes_gaseosa_jugo_ml)\n",
    "        unidades_caja_val = random.choice(unidades_por_caja_gaseosa_jugo)\n",
    "        nombre_producto_str = f\"{sabor} {volumen_ml_val}mL x {unidades_caja_val}uds\"\n",
    "    elif categoria == 'Bebida Energética':\n",
    "        volumen_ml_val = random.choice(volumenes_energia_ml)\n",
    "        unidades_caja_val = random.choice(unidades_por_caja_energia)\n",
    "        nombre_producto_str = f\"{sabor} {volumen_ml_val}mL x {unidades_caja_val}uds\"\n",
    "    elif categoria == 'Agua':\n",
    "        volumen_ml_val = random.choice(volumenes_agua_ml)\n",
    "        unidades_caja_val = random.choice(unidades_por_caja_agua)\n",
    "        nombre_producto_str = f\"{sabor} {volumen_ml_val // 1000}L x {unidades_caja_val}uds\" if volumen_ml_val >= 1000 else f\"{sabor} {volumen_ml_val}mL x {unidades_caja_val}uds\"\n",
    "    elif categoria == 'Bebida de Té':\n",
    "        volumen_ml_val = random.choice([300, 500, 1000])\n",
    "        unidades_caja_val = random.choice([1, 6, 12])\n",
    "        nombre_producto_str = f\"{sabor} {volumen_ml_val}mL x {unidades_caja_val}uds\"\n",
    "\n",
    "    productos.append({\n",
    "        'producto_id': i + 1,\n",
    "        'nombre_producto': nombre_producto_str,\n",
    "        'categoria': categoria,\n",
    "        'marca': marca,\n",
    "        'volumen_ml_base': volumen_ml_val,\n",
    "        'unidades_caja_base': unidades_caja_val\n",
    "    })\n",
    "df_productos = pl.DataFrame(productos)\n",
    "\n",
    "# --- 4. Price History Table ---\n",
    "historico_precios = []\n",
    "hist_precio_id_counter = 1\n",
    "\n",
    "precios_por_ml_base_categoria = {\n",
    "    'Agua': 2.5, 'Gaseosa': 3.5, 'Jugo': 4.0, 'Bebida Energética': 10.0, 'Bebida de Té': 6.0\n",
    "}\n",
    "costos_por_ml_base_categoria = {\n",
    "    'Agua': 1.0, 'Gaseosa': 1.8, 'Jugo': 2.2, 'Bebida Energética': 4.5, 'Bebida de Té': 3.0\n",
    "}\n",
    "\n",
    "for producto_row in df_productos.iter_rows(named=True):\n",
    "    current_date = start_date_data.replace(day=1)\n",
    "\n",
    "    volumen_para_calculo = producto_row['volumen_ml_base'] if producto_row['volumen_ml_base'] > 0 else 1000\n",
    "    unidades_para_calculo = producto_row['unidades_caja_base'] if producto_row['unidades_caja_base'] > 0 else 1\n",
    "    categoria = producto_row['categoria']\n",
    "\n",
    "    base_precio_ml_actual = precios_por_ml_base_categoria.get(categoria, 3.0)\n",
    "    base_costo_ml_actual = costos_por_ml_base_categoria.get(categoria, 1.8)\n",
    "\n",
    "    initial_precio_unitario = round(base_precio_ml_actual * volumen_para_calculo * unidades_para_calculo, 2)\n",
    "    initial_costo_variable = round(base_costo_ml_actual * volumen_para_calculo * unidades_para_calculo, 2)\n",
    "\n",
    "    while current_date <= end_date_data:\n",
    "        historico_precios.append({\n",
    "            'historico_precio_id': hist_precio_id_counter,\n",
    "            'producto_id': producto_row['producto_id'],\n",
    "            'fecha_actualizacion': current_date.date(),\n",
    "            'precio_base': initial_precio_unitario,\n",
    "            'costo_variable': initial_costo_variable\n",
    "        })\n",
    "        hist_precio_id_counter += 1\n",
    "\n",
    "        incremento_porcentaje_precio = random.uniform(0.00, 0.02)\n",
    "        incremento_porcentaje_costo = random.uniform(0.00, 0.015)\n",
    "\n",
    "        initial_precio_unitario = round(initial_precio_unitario * (1 + incremento_porcentaje_precio), 2)\n",
    "        initial_costo_variable = round(initial_costo_variable * (1 + incremento_porcentaje_costo), 2)\n",
    "\n",
    "        if initial_costo_variable >= initial_precio_unitario:\n",
    "            initial_costo_variable = round(initial_precio_unitario * 0.7, 2)\n",
    "\n",
    "        if current_date.month == 12:\n",
    "            current_date = current_date.replace(year=current_date.year + 1, month=1)\n",
    "        else:\n",
    "            current_date = current_date.replace(month=current_date.month + 1)\n",
    "\n",
    "df_historico_precios = pl.DataFrame(historico_precios)\n",
    "\n",
    "# --- 5. Channels Table ---\n",
    "canales = {\n",
    "    'canal_id': range(1, n_canales + 1),\n",
    "    'nombre_canal': ['Supermercado', 'Tienda de Conveniencia', 'E-commerce', 'Vending Machine', 'Hipermercado'],\n",
    "    'tipo_canal': ['Físico', 'Físico', 'Online', 'Físico', 'Físico']\n",
    "}\n",
    "df_canales = pl.DataFrame(canales)\n",
    "\n",
    "# --- 6. Promotions Table ---\n",
    "promociones_data = []\n",
    "for i in range(1, n_promociones + 1):\n",
    "    fecha_inicio = fake.date_between(start_date=start_date_data - timedelta(days=180), end_date=end_date_data - timedelta(days=90))\n",
    "    fecha_fin = fecha_inicio + timedelta(days=random.randint(30, 180))\n",
    "\n",
    "    if fecha_fin > end_date_data.date():\n",
    "        fecha_fin = end_date_data.date()\n",
    "\n",
    "    promociones_data.append({\n",
    "        'promocion_id': i,\n",
    "        'nombre_promocion': f\"Promo {i}\",\n",
    "        'descuento_porcentaje': np.random.randint(5, 30),\n",
    "        'fecha_inicio': fecha_inicio,\n",
    "        'fecha_fin': fecha_fin\n",
    "    })\n",
    "df_promociones = pl.DataFrame(promociones_data)\n",
    "\n",
    "# --- 7. Inventory Table ---\n",
    "inventarios = {\n",
    "    'inventario_id': range(1, n_inventarios + 1),\n",
    "    'producto_id': np.random.choice(df_productos['producto_id'], n_inventarios),\n",
    "    'region_id': np.random.choice(df_regiones['region_id'], n_inventarios),\n",
    "    'stock': np.random.randint(5, 200, n_inventarios),\n",
    "    'fecha_actualizacion': [fake.date_between(start_date='-6m', end_date='today') for _ in range(n_inventarios)]\n",
    "}\n",
    "df_inventarios = pl.DataFrame(inventarios)\n",
    "\n",
    "# --- 8. Sales Table (with seasonality and controlled monthly quantity per product) ---\n",
    "sales_data_chunks = []\n",
    "venta_id_counter_final = 1\n",
    "\n",
    "# Store monthly product state for EPD calculation and target setting\n",
    "last_product_monthly_state = {}   # {(producto_id, 'YYYY-MM'): {'precio': P_avg, 'cantidad': Q_total}}\n",
    "monthly_product_target_quantities = {} # {(producto_id, 'YYYY-MM'): target_total_quantity for the current month}\n",
    "daily_product_sales_distribution = {} # {(producto_id, 'YYYY-MM-DD'): target_daily_quantity}\n",
    "\n",
    "\n",
    "# Pre-calculate product categories for faster lookup\n",
    "product_category_map = {row['producto_id']: row['categoria'] for row in df_productos.select(['producto_id', 'categoria']).iter_rows(named=True)}\n",
    "\n",
    "total_days_simulation = (end_date_data - start_date_data).days + 1\n",
    "\n",
    "# Define the consistent schema for daily sales data upfront\n",
    "daily_sales_schema = {\n",
    "    'venta_id': pl.Int64,\n",
    "    'fecha': pl.String,\n",
    "    'cliente_id': pl.Int64,\n",
    "    'producto_id': pl.Int64,\n",
    "    'cantidad': pl.Int64,\n",
    "    'canal_id': pl.Int64,\n",
    "    'region_id': pl.Int64,\n",
    "    'promocion_id': pl.Int64,\n",
    "    'historico_precio_id': pl.Int64\n",
    "}\n",
    "\n",
    "# Initial monthly trend multiplier (for overall sales volume)\n",
    "monthly_sales_trend_multiplier = 1.0\n",
    "last_month_year = None\n",
    "\n",
    "\n",
    "# Use tqdm for progress visualization\n",
    "for day_offset in tqdm(range(total_days_simulation), desc=\"Generando datos de ventas\"):\n",
    "    current_sale_date = start_date_data + timedelta(days=day_offset)\n",
    "    current_sale_date_str = current_sale_date.strftime('%Y-%m-%d')\n",
    "    current_month_str = current_sale_date.strftime('%Y-%m')\n",
    "\n",
    "    month = current_sale_date.month\n",
    "    year = current_sale_date.year\n",
    "\n",
    "    # --- Monthly Aggregated Quantity Control Logic ---\n",
    "    if current_month_str != last_month_year:\n",
    "        # 1. Update last_product_monthly_state with actual sales from the *just finished* month\n",
    "        if last_month_year is not None:\n",
    "            prev_month_end = current_sale_date - timedelta(days=1)\n",
    "            prev_month_start = prev_month_end.replace(day=1)\n",
    "            prev_month_str_for_key = prev_month_start.strftime('%Y-%m')\n",
    "\n",
    "            # Filter sales_data_chunks for the previous month\n",
    "            df_prev_month_sales_list = []\n",
    "            for chunk_df in sales_data_chunks:\n",
    "                # Assuming 'fecha' in chunks is always in '%Y-%m-%d' format string\n",
    "                chunk_filtered = chunk_df.filter(\n",
    "                    (pl.col('fecha').str.strptime(pl.Date, '%Y-%m-%d') >= prev_month_start.date()) &\n",
    "                    (pl.col('fecha').str.strptime(pl.Date, '%Y-%m-%d') <= prev_month_end.date())\n",
    "                )\n",
    "                if not chunk_filtered.is_empty():\n",
    "                    df_prev_month_sales_list.append(chunk_filtered)\n",
    "\n",
    "            if df_prev_month_sales_list:\n",
    "                df_prev_month_sales_combined = pl.concat(df_prev_month_sales_list, how=\"vertical_relaxed\")\n",
    "\n",
    "                df_prev_month_sales_combined = df_prev_month_sales_combined.join(\n",
    "                    df_historico_precios.select(['historico_precio_id', 'precio_base']),\n",
    "                    on='historico_precio_id',\n",
    "                    how='left'\n",
    "                )\n",
    "\n",
    "                monthly_summary = df_prev_month_sales_combined.group_by('producto_id').agg(\n",
    "                    pl.sum('cantidad').alias('cantidad_total'),\n",
    "                    pl.mean('precio_base').alias('precio_promedio')\n",
    "                )\n",
    "\n",
    "                for row in monthly_summary.iter_rows(named=True):\n",
    "                    key = (row['producto_id'], prev_month_str_for_key)\n",
    "                    last_product_monthly_state[key] = {\n",
    "                        'precio': row['precio_promedio'],\n",
    "                        'cantidad': row['cantidad_total']\n",
    "                    }\n",
    "\n",
    "        # 2. Calculate TARGET monthly quantities for each product for the *current* month\n",
    "        monthly_product_target_quantities.clear() # Reset for the new month\n",
    "        daily_product_sales_distribution.clear() # Reset for the new month\n",
    "\n",
    "        days_in_current_month = (current_sale_date.replace(month=current_sale_date.month % 12 + 1, day=1) - timedelta(days=1)).day\n",
    "\n",
    "        # Modificada la lógica de EPD y cambio mensual\n",
    "        for prod_id in df_productos['producto_id'].to_list():\n",
    "            prev_month_key = (prod_id, (current_sale_date - timedelta(days=current_sale_date.day)).replace(day=1).strftime('%Y-%m'))\n",
    "\n",
    "            # Get previous month's actual total quantity and average price\n",
    "            prev_month_total_quantity = last_product_monthly_state.get(prev_month_key, {'cantidad': 0})['cantidad']\n",
    "            prev_month_avg_price = last_product_monthly_state.get(prev_month_key, {'precio': 0})['precio']\n",
    "\n",
    "            # Si no hay datos del mes anterior, inicializar con una base razonable\n",
    "            if prev_month_total_quantity == 0:\n",
    "                base_target_quantity = (n_ventas / n_productos / total_days_simulation) * days_in_current_month * 2\n",
    "            else:\n",
    "                base_target_quantity = prev_month_total_quantity\n",
    "\n",
    "            # Obtener precio actual para cálculo de EPD\n",
    "            current_price_record = df_historico_precios.filter(\n",
    "                (pl.col('producto_id') == prod_id) &\n",
    "                (pl.col('fecha_actualizacion').cast(pl.Date) <= current_sale_date.date())\n",
    "            ).sort('fecha_actualizacion', descending=True).head(1)\n",
    "\n",
    "            current_prod_price = current_price_record['precio_base'].item() if not current_price_record.is_empty() else 100\n",
    "\n",
    "            # Calcular cambio de precio y EPD\n",
    "            porcentaje_cambio_precio = 0\n",
    "            if prev_month_avg_price > 0:\n",
    "                porcentaje_cambio_precio = (current_prod_price - prev_month_avg_price) / prev_month_avg_price\n",
    "\n",
    "            categoria_producto = product_category_map.get(prod_id)\n",
    "            rango_epd = elasticidades_por_categoria.get(categoria_producto, {'min': -1.0, 'max': -2.0})\n",
    "            epd_objetivo = random.uniform(rango_epd['min'], rango_epd['max'])\n",
    "            \n",
    "            # Aplicar elasticidad positiva con menor probabilidad\n",
    "            if random.random() < prob_elasticidad_positiva:\n",
    "                epd_objetivo = random.uniform(rango_elasticidad_positiva['min'], rango_elasticidad_positiva['max'])\n",
    "\n",
    "            # Calcular el efecto de la elasticidad\n",
    "            epd_influenced_change = epd_objetivo * porcentaje_cambio_precio\n",
    "\n",
    "            # Verificar promociones activas para el producto\n",
    "            promociones_activas = df_promociones.filter(\n",
    "                (pl.col('fecha_inicio').cast(pl.Date) <= current_sale_date.date()) &\n",
    "                (pl.col('fecha_fin').cast(pl.Date) >= current_sale_date.date())\n",
    "            )\n",
    "\n",
    "            # Ajustar el efecto de la elasticidad si hay promociones\n",
    "            if not promociones_activas.is_empty():\n",
    "                descuento_promedio = promociones_activas['descuento_porcentaje'].mean() / 100\n",
    "                promotion_boost = random.uniform(MIN_PROMOTION_BOOST, MAX_PROMOTION_BOOST)\n",
    "                epd_influenced_change = epd_influenced_change * PROMOTION_ELASTICITY_MULTIPLIER * (1 + descuento_promedio)\n",
    "                base_monthly_change_factor = promotion_boost\n",
    "\n",
    "            # Combinar influencia de EPD con tendencia mensual base\n",
    "            base_monthly_change_factor = random.uniform(0.95, 1.05) * (1 + epd_influenced_change)\n",
    "\n",
    "            # Aplicar límites a los cambios base\n",
    "            clipped_base_change_factor = np.clip(\n",
    "                base_monthly_change_factor,\n",
    "                1 - MAX_PERCENT_CHANGE_PER_MONTH_PRODUCT_AGGREGATE,\n",
    "                1 + MAX_PERCENT_CHANGE_PER_MONTH_PRODUCT_AGGREGATE\n",
    "            )\n",
    "\n",
    "            # Aplicar multiplicador estacional\n",
    "            current_seasonal_multiplier = seasonal_multipliers.get(month, 1.0)\n",
    "            \n",
    "            # Ajustar el multiplicador estacional según la categoría del producto\n",
    "            if categoria_producto in ['Agua', 'Gaseosa', 'Bebida de Té']:\n",
    "                # Productos más sensibles a la temporada cálida\n",
    "                if month in [6, 7, 8]:  # Meses de verano\n",
    "                    current_seasonal_multiplier *= 1.2\n",
    "        \n",
    "            # Productos más sensibles a la temporada navideña\n",
    "            if month == 12:\n",
    "                current_seasonal_multiplier *= 1.15\n",
    "\n",
    "            final_monthly_change_factor = clipped_base_change_factor * current_seasonal_multiplier\n",
    "\n",
    "            target_monthly_quantity = int(base_target_quantity * final_monthly_change_factor)\n",
    "            target_monthly_quantity = max(1, target_monthly_quantity)\n",
    "\n",
    "            monthly_product_target_quantities[(prod_id, current_month_str)] = target_monthly_quantity\n",
    "\n",
    "        # 3. Distribute monthly target quantities across days of the current month\n",
    "        # This will be used to guide daily sales generation\n",
    "        for prod_id, total_monthly_q in monthly_product_target_quantities.items():\n",
    "            if prod_id[1] != current_month_str: # Only process for the current month\n",
    "                continue\n",
    "\n",
    "            base_daily_q = total_monthly_q / days_in_current_month\n",
    "\n",
    "            for d_offset_in_month in range(days_in_current_month):\n",
    "                date_in_month = current_sale_date.replace(day=1) + timedelta(days=d_offset_in_month)\n",
    "                daily_q = base_daily_q * random.uniform(1 - DAILY_QUANTITY_FLUCTUATION_FACTOR, 1 + DAILY_QUANTITY_FLUCTUATION_FACTOR)\n",
    "                daily_product_sales_distribution[(prod_id[0], date_in_month.strftime('%Y-%m-%d'))] = max(1, int(daily_q))\n",
    "\n",
    "        last_month_year = current_month_str\n",
    "\n",
    "    # --- Daily Sales Generation based on Calculated Monthly Targets ---\n",
    "\n",
    "    # Calculate total sales for today based on overall average and trend\n",
    "    base_sales_per_day = n_ventas / total_days_simulation\n",
    "    overall_daily_sales_num_multiplier = random.uniform(0.95, 1.05) # Small daily fluctuation for number of sales\n",
    "    num_sales_today = int(base_sales_per_day * monthly_sales_trend_multiplier * overall_daily_sales_num_multiplier)\n",
    "    num_sales_today = max(1, num_sales_today) # Ensure at least one sale\n",
    "\n",
    "    daily_sales_data = []\n",
    "\n",
    "    # Products and their remaining target quantities for TODAY\n",
    "    current_day_product_targets = {\n",
    "        prod_id: daily_product_sales_distribution.get((prod_id, current_sale_date_str), 0)\n",
    "        for prod_id in df_productos['producto_id'].to_list()\n",
    "    }\n",
    "\n",
    "    # Create a list of products to consider for sales today, prioritizing those with higher remaining targets\n",
    "    products_for_today_sales = [\n",
    "        p_id for p_id, target_q in current_day_product_targets.items() if target_q > 0\n",
    "    ]\n",
    "\n",
    "    for _ in range(num_sales_today):\n",
    "        product_id = None\n",
    "        if products_for_today_sales: # If there are products with remaining daily targets\n",
    "            remaining_quantities = np.array([current_day_product_targets[p_id] for p_id in products_for_today_sales])\n",
    "            if remaining_quantities.sum() > 0:\n",
    "                probabilities = remaining_quantities / remaining_quantities.sum()\n",
    "                product_id = np.random.choice(products_for_today_sales, p=probabilities)\n",
    "            else: # Fallback, should be rare if products_for_today_sales is non-empty\n",
    "                product_id = random.choice(df_productos['producto_id'].to_list())\n",
    "        else:\n",
    "            # If all product daily targets are fulfilled for today, pick a random product from all products\n",
    "            product_id = random.choice(df_productos['producto_id'].to_list())\n",
    "\n",
    "\n",
    "        cliente_id = np.random.choice(df_clientes['cliente_id'])\n",
    "        region_id = np.random.choice(regiones_para_seleccion, p=prob_regiones_para_seleccion)\n",
    "        canal_id = np.random.choice(df_canales['canal_id'])\n",
    "\n",
    "        # Lógica de promociones\n",
    "        promociones_validas_hoy = df_promociones.filter(\n",
    "            (pl.col('fecha_inicio').cast(pl.Date) <= current_sale_date.date()) &\n",
    "            (pl.col('fecha_fin').cast(pl.Date) >= current_sale_date.date())\n",
    "        )\n",
    "\n",
    "        promocion_id = None\n",
    "        if not promociones_validas_hoy.is_empty() and random.random() < 0.5:\n",
    "            promocion_id = random.choice(promociones_validas_hoy['promocion_id'].to_list())\n",
    "\n",
    "        # Búsqueda de precios\n",
    "        precio_registro = df_historico_precios.filter(\n",
    "            (pl.col('producto_id') == product_id) &\n",
    "            (pl.col('fecha_actualizacion').cast(pl.Date) <= current_sale_date.date())\n",
    "        ).sort('fecha_actualizacion', descending=True).head(1)\n",
    "\n",
    "        if precio_registro.is_empty():\n",
    "            # Fallback if no price found (should be rare with good price history generation)\n",
    "            # You might want to log this or assign a default price if it occurs frequently\n",
    "            continue # Skip this sale if no price can be determined for the product\n",
    "\n",
    "        historico_precio_id = precio_registro['historico_precio_id'].item()\n",
    "\n",
    "        # Determine quantity for this specific sale\n",
    "        # Try to take a chunk from the remaining daily target\n",
    "        quantity = random.randint(MIN_QUANTITY_PER_SALE, MAX_QUANTITY_PER_SALE)\n",
    "\n",
    "        # If there's a daily target, adjust quantity to meet it\n",
    "        if current_day_product_targets.get(product_id, 0) > 0:\n",
    "            quantity_for_sale_attempt = random.randint(MIN_QUANTITY_PER_SALE, MAX_QUANTITY_PER_SALE)\n",
    "            quantity = min(quantity_for_sale_attempt, current_day_product_targets[product_id])\n",
    "            quantity = max(1, quantity) # Ensure at least 1 unit if target > 0\n",
    "\n",
    "            current_day_product_targets[product_id] -= quantity\n",
    "            if current_day_product_targets[product_id] <= 0:\n",
    "                # Remove product from list only if its target is truly met\n",
    "                if product_id in products_for_today_sales: # Check before removing\n",
    "                    products_for_today_sales.remove(product_id)\n",
    "\n",
    "        daily_sales_data.append({\n",
    "            'venta_id': venta_id_counter_final,\n",
    "            'fecha': current_sale_date_str,\n",
    "            'cliente_id': cliente_id,\n",
    "            'producto_id': product_id,\n",
    "            'cantidad': quantity,\n",
    "            'canal_id': canal_id,\n",
    "            'region_id': region_id,\n",
    "            'promocion_id': promocion_id,\n",
    "            'historico_precio_id': historico_precio_id\n",
    "        })\n",
    "        venta_id_counter_final += 1\n",
    "        \n",
    "        # Check if total sales reached within the loop to break early if desired\n",
    "        if venta_id_counter_final > n_ventas:\n",
    "            break # Break from the daily sales loop if we have enough sales overall\n",
    "\n",
    "    if daily_sales_data:\n",
    "        sales_data_chunks.append(pl.DataFrame(daily_sales_data, schema=daily_sales_schema))\n",
    "    \n",
    "    # Check if total sales reached, and if so, break from the main daily loop\n",
    "    if venta_id_counter_final > n_ventas:\n",
    "        print(f\"Objetivo de {n_ventas} ventas alcanzado. Deteniendo la generación de datos.\")\n",
    "        break\n",
    "\n",
    "\n",
    "# Concatenación final de todas las ventas\n",
    "# Use take(n_ventas) to ensure the total number of sales does not exceed the parameter\n",
    "# Use slice to ensure exactly n_ventas if possible\n",
    "df_ventas = pl.concat(sales_data_chunks, how=\"vertical_relaxed\")\n",
    "df_ventas = df_ventas.slice(0, n_ventas) # Get exactly n_ventas rows if available\n",
    "\n",
    "# --- Guardar en CSV ---\n",
    "df_clientes.write_csv('clientes.csv')\n",
    "df_productos.write_csv('productos.csv')\n",
    "df_historico_precios.write_csv('historico_precios.csv')\n",
    "df_canales.write_csv('canales.csv')\n",
    "df_regiones.write_csv('regiones.csv')\n",
    "df_promociones.write_csv('promociones.csv')\n",
    "df_inventarios.write_csv('inventarios.csv')\n",
    "df_ventas.write_csv('ventas.csv')\n",
    "\n",
    "print(f\"\\nConjuntos de datos generados y guardados como CSV.\")\n",
    "print(f\"Total de ventas: {len(df_ventas)}\")\n",
    "print(f\"Total de productos: {len(df_productos)}\")\n",
    "print(f\"Total de entradas de historial de precios: {len(df_historico_precios)}\")\n",
    "print(f\"Total de clientes: {len(df_clientes)}\")\n",
    "print(f\"Total de regiones: {len(df_regiones)}\")\n",
    "print(f\"Total de canales: {len(df_canales)}\")\n",
    "print(f\"Total de promociones: {len(df_promociones)}\")\n",
    "print(f\"Total de entradas de inventario: {len(df_inventarios)}\")\n",
    "\n",
    "# --- Opcional: Verificación de la variación mensual (para depuración) ---\n",
    "df_ventas_temp = df_ventas.with_columns(pl.col('fecha').str.strptime(pl.Date, '%Y-%m-%d'))\n",
    "monthly_product_sales = df_ventas_temp.group_by(['producto_id', pl.col('fecha').dt.year().alias('año'), pl.col('fecha').dt.month().alias('mes')]).agg(\n",
    "    pl.sum('cantidad').alias('cantidad_total_mes')\n",
    ").sort(['producto_id', 'año', 'mes'])\n",
    "\n",
    "print(\"\\nVerificación de variación mensual (primeros 5 productos):\")\n",
    "for product_id in range(1, 6): # Check for first 5 products\n",
    "    product_sales = monthly_product_sales.filter(pl.col('producto_id') == product_id)\n",
    "    if product_sales.height > 1:\n",
    "        print(f\"Producto {product_id}:\")\n",
    "        for i in range(1, product_sales.height):\n",
    "            q_prev = product_sales[i-1, 'cantidad_total_mes']\n",
    "            q_curr = product_sales[i, 'cantidad_total_mes']\n",
    "            if q_prev > 0:\n",
    "                change_percent = ((q_curr - q_prev) / q_prev) * 100\n",
    "                print(f\"  {product_sales[i-1, 'año']}-{product_sales[i-1, 'mes']} a {product_sales[i, 'año']}-{product_sales[i, 'mes']}: {change_percent:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
