{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c70c51d",
   "metadata": {},
   "source": [
    "## MODELO DE REGRESIÓN LOGÍSTICA PARA CLASIFICACIÓN DE SOLICITUDES DE CRÉDITO\n",
    "#### NOTEBOOK: Entrenar_Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6c05c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, when, count, isnan, isnull, expr\n",
    "from pyspark.sql.types import *\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear o obtener la sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ClasificadorCredito\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Sesión de Spark activa:\", spark)\n",
    "\n",
    "# Cargar datos con manejo de errores\n",
    "try:\n",
    "    df = spark.read.format(\"delta\").load(\"Tables/solicitudes_processed\")\n",
    "    print(f\"Datos cargados exitosamente. Total de registros: {df.count()}\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error al cargar los datos: {str(e)}\")\n",
    "\n",
    "# Filtrar solo Aprobado/Rechazado y crear etiquetas\n",
    "df = df.filter(col(\"estado_solicitud\").isin(\"Aprobado\", \"Rechazado\"))\n",
    "df = df.withColumn(\"label\", when(col(\"estado_solicitud\") == \"Aprobado\", 1.0).otherwise(0.0))\n",
    "\n",
    "# Verificar distribución de clases\n",
    "class_distribution = df.groupBy(\"estado_solicitud\").count()\n",
    "print(\"Distribución de clases:\")\n",
    "class_distribution.show()\n",
    "\n",
    "# Definir columnas de entrada\n",
    "input_cols = [\"edad\", \"ingresos_anuales\", \"puntaje_crediticio\", \"deuda_actual\",\n",
    "              \"antiguedad_laboral\", \"historial_pagos_encoded\", \"estado_civil_encoded\",\n",
    "              \"tipo_empleo_encoded\", \"numero_dependientes\"]\n",
    "\n",
    "# Análisis de valores nulos antes de la limpieza\n",
    "print(\"\\nAnálisis de valores nulos antes de la limpieza:\")\n",
    "for column in input_cols:\n",
    "    null_count = df.filter(col(column).isNull() | isnan(col(column))).count()\n",
    "    total = df.count()\n",
    "    null_percentage = (null_count / total) * 100\n",
    "    print(f\"{column}: {null_count} nulos ({null_percentage:.2f}%)\")\n",
    "\n",
    "# Manejar valores nulos con estrategia más sofisticada\n",
    "for col_name in input_cols:\n",
    "    # Usar la mediana para variables numéricas\n",
    "    if col_name in [\"edad\", \"ingresos_anuales\", \"puntaje_crediticio\", \"deuda_actual\", \"antiguedad_laboral\"]:\n",
    "        median_value = df.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "        df = df.fillna(median_value, subset=[col_name])\n",
    "    else:\n",
    "        # Usar 0 para variables categóricas codificadas\n",
    "        df = df.fillna(0, subset=[col_name])\n",
    "\n",
    "# Verificar que no queden nulos\n",
    "null_check = df.select([count(when(col(c).isNull() | isnan(col(c)), c)).alias(c) for c in input_cols])\n",
    "print(\"\\nVerificación final de valores nulos:\")\n",
    "null_check.show()\n",
    "\n",
    "# Dividir datos con estratificación\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=123)\n",
    "print(f\"Datos de entrenamiento: {train_df.count()} registros\")\n",
    "print(f\"Datos de prueba: {test_df.count()} registros\")\n",
    "\n",
    "# Preparar características\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=input_cols,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"  # Manejo explícito de valores inválidos\n",
    ")\n",
    "\n",
    "# Configurar modelo con hiperparámetros y umbral personalizado\n",
    "lr = LogisticRegression(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=10,\n",
    "    regParam=0.1,  # Regularización L2\n",
    "    elasticNetParam=0.2,  # Elastic Net mixing (0=Ridge, 1=Lasso)\n",
    "    standardization=True,  # Estandarizar características\n",
    "    threshold=0.5  # Umbral de clasificación inicial\n",
    ")\n",
    "\n",
    "# Crear y entrenar pipeline\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "try:\n",
    "    print(\"Iniciando entrenamiento del modelo...\")\n",
    "    clf_model = pipeline.fit(train_df)\n",
    "    print(\"Modelo entrenado exitosamente\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error durante el entrenamiento: {str(e)}\")\n",
    "\n",
    "# Evaluación exhaustiva del modelo\n",
    "predictions = clf_model.transform(test_df)\n",
    "\n",
    "# Múltiples métricas de evaluación\n",
    "metrics = {}\n",
    "\n",
    "# ROC AUC\n",
    "evaluator_auc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "metrics['auc'] = evaluator_auc.evaluate(predictions)\n",
    "\n",
    "# Precisión\n",
    "evaluator_precision = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedPrecision\"  # Cambiado de \"precision\" a \"weightedPrecision\"\n",
    ")\n",
    "metrics['precision'] = evaluator_precision.evaluate(predictions)\n",
    "\n",
    "# Recall\n",
    "evaluator_recall = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedRecall\"  # Cambiado de \"recall\" a \"weightedRecall\"\n",
    ")\n",
    "metrics['recall'] = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "# Calcular y visualizar matriz de confusión\n",
    "def calcular_matriz_confusion(predictions):\n",
    "    # Convertir predicciones a pandas para mejor manipulación\n",
    "    pred_pd = predictions.select(['label', 'prediction']).toPandas()\n",
    "    conf_matrix = pd.crosstab(pred_pd['label'], pred_pd['prediction'], margins=True)\n",
    "    \n",
    "    # Calcular métricas específicas\n",
    "    tn = conf_matrix.iloc[0,0]\n",
    "    fp = conf_matrix.iloc[0,1]\n",
    "    fn = conf_matrix.iloc[1,0]\n",
    "    tp = conf_matrix.iloc[1,1]\n",
    "    \n",
    "    # Calcular métricas adicionales\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    f1_score = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
    "    \n",
    "    return conf_matrix, {'specificity': specificity, 'npv': npv, 'f1_score': f1_score}\n",
    "\n",
    "# Función para encontrar el mejor umbral\n",
    "def optimizar_umbral(predictions, num_thresholds=10):\n",
    "    thresholds = np.linspace(0.1, 0.9, num_thresholds)\n",
    "    resultados = []\n",
    "    \n",
    "    pred_pd = predictions.select(['label', 'probability']).toPandas()\n",
    "    y_true = pred_pd['label']\n",
    "    probas = np.array([p[1] for p in pred_pd['probability']])\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (probas >= threshold).astype(int)\n",
    "        tn = sum((y_true == 0) & (y_pred == 0))\n",
    "        fp = sum((y_true == 0) & (y_pred == 1))\n",
    "        fn = sum((y_true == 1) & (y_pred == 0))\n",
    "        tp = sum((y_true == 1) & (y_pred == 1))\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        resultados.append({\n",
    "            'threshold': threshold,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "# Calcular matriz de confusión y métricas adicionales\n",
    "conf_matrix, metricas_adicionales = calcular_matriz_confusion(predictions)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nMétricas Adicionales:\")\n",
    "for nombre, valor in metricas_adicionales.items():\n",
    "    print(f\"{nombre}: {valor:.4f}\")\n",
    "\n",
    "# Optimizar umbral\n",
    "resultados_umbrales = optimizar_umbral(predictions)\n",
    "mejor_umbral = resultados_umbrales.loc[resultados_umbrales['f1_score'].idxmax()]\n",
    "print(f\"\\nMejor umbral encontrado: {mejor_umbral['threshold']:.3f} (F1-Score: {mejor_umbral['f1_score']:.3f})\")\n",
    "\n",
    "# Actualizar métricas para incluir la matriz de confusión\n",
    "metrics['specificity'] = metricas_adicionales['specificity']\n",
    "metrics['npv'] = metricas_adicionales['npv']\n",
    "metrics['f1_score'] = metricas_adicionales['f1_score']\n",
    "metrics['mejor_umbral'] = float(mejor_umbral['threshold'])\n",
    "\n",
    "# Imprimir métricas\n",
    "print(\"\\nMétricas de evaluación:\")\n",
    "for metric_name, value in metrics.items():\n",
    "    print(f\"{metric_name.upper()}: {value:.4f}\")\n",
    "\n",
    "# Guardar modelo con manejo de errores\n",
    "try:\n",
    "    # Intentar guardar en una ruta del lakehouse\n",
    "    model_path = \"Tables/Models/ClasificadorCredito\"\n",
    "    print(f\"Intentando guardar el modelo en: {model_path}\")\n",
    "    clf_model.write().overwrite().save(model_path)\n",
    "    print(f\"Modelo guardado exitosamente en {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el modelo en el lakehouse: {str(e)}\")\n",
    "    # Intentar guardar en una ruta relativa\n",
    "    try:\n",
    "        local_path = \"./models/ClasificadorCredito\"\n",
    "        print(f\"Intentando guardar el modelo en ruta relativa: {local_path}\")\n",
    "        clf_model.write().overwrite().save(local_path)\n",
    "        print(f\"Modelo guardado exitosamente en ruta relativa: {local_path}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error al guardar en ruta relativa: {str(e2)}\")\n",
    "        print(\"Sugerencia: Verifica los permisos y la configuración del lakehouse en Fabric\")\n",
    "        raise\n",
    "\n",
    "# Actualizar el DataFrame de métricas para incluir nuevas métricas\n",
    "metrics_df = spark.createDataFrame([(\n",
    "    datetime.now(),\n",
    "    float(metrics['auc']),\n",
    "    float(metrics['precision']),\n",
    "    float(metrics['recall']),\n",
    "    float(metrics['specificity']),\n",
    "    float(metrics['npv']),\n",
    "    float(metrics['f1_score']),\n",
    "    float(metrics['mejor_umbral'])\n",
    ")], [\"fecha_entrenamiento\", \"auc\", \"precision\", \"recall\", \"specificity\", \"npv\", \"f1_score\", \"mejor_umbral\"])\n",
    "\n",
    "# Guardar métricas actualizadas\n",
    "metrics_df.write.mode(\"append\").format(\"delta\").save(\"Tables/precision_clasificador\")\n",
    "\n",
    "# Notificar resultados (usando variable de entorno para el webhook)\n",
    "discord_webhook_url = os.getenv('DISCORD_WEBHOOK_URL', \"XXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "# Crear mensaje de éxito\n",
    "def crear_mensaje_exito(metrics):\n",
    "    return {\n",
    "        \"embeds\": [\n",
    "            {\n",
    "                \"title\": \"✅ Reentrenamiento Exitoso - RiskApp\",\n",
    "                \"description\": \"El modelo de clasificación ha sido reentrenado exitosamente.\",\n",
    "                \"color\": 3066993,\n",
    "                \"fields\": [\n",
    "                    {\"name\": \"AUC\", \"value\": f\"{metrics['auc']:.4f}\", \"inline\": True},\n",
    "                    {\"name\": \"Precisión\", \"value\": f\"{metrics['precision']:.4f}\", \"inline\": True},\n",
    "                    {\"name\": \"Recall\", \"value\": f\"{metrics['recall']:.4f}\", \"inline\": True},\n",
    "                    {\"name\": \"Especificidad\", \"value\": f\"{metrics['specificity']:.4f}\", \"inline\": True},\n",
    "                    {\"name\": \"VPN\", \"value\": f\"{metrics['npv']:.4f}\", \"inline\": True},\n",
    "                    {\"name\": \"F1-Score\", \"value\": f\"{metrics['f1_score']:.4f}\", \"inline\": True},\n",
    "                    {\"name\": \"Mejor Umbral\", \"value\": f\"{metrics['mejor_umbral']:.3f}\", \"inline\": True}\n",
    "                ],\n",
    "                \"footer\": {\"text\": \"RiskApp - Sistema de Monitoreo\"},\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Crear mensaje de error\n",
    "def crear_mensaje_error(error):\n",
    "    return {\n",
    "        \"embeds\": [\n",
    "            {\n",
    "                \"title\": \"❌ Error en el Reentrenamiento - RiskApp\",\n",
    "                \"description\": f\"Se produjo un error durante el reentrenamiento: {error}\",\n",
    "                \"color\": 15158332,  # Rojo\n",
    "                \"footer\": {\"text\": \"RiskApp - Sistema de Monitoreo\"},\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Enviar notificación\n",
    "def enviar_notificacion(mensaje):\n",
    "    try:\n",
    "        response = requests.post(discord_webhook_url, json=mensaje)\n",
    "        response.raise_for_status()\n",
    "        print(\"\\nNotificación enviada exitosamente a Discord\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al enviar notificación: {str(e)}\")\n",
    "\n",
    "# Enviar mensaje de éxito o error\n",
    "try:\n",
    "    mensaje = crear_mensaje_exito(metrics)\n",
    "    enviar_notificacion(mensaje)\n",
    "except Exception as e:\n",
    "    mensaje = crear_mensaje_error(str(e))\n",
    "    enviar_notificacion(mensaje)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
