{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT TO SPEECH FROM \"https://huggingface.co/datasets/charris/hubert_process_filter_spotify\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset desde charris/hubert_process_filter_spotify...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "import torchaudio\n",
    "import torch\n",
    "import whisper\n",
    "import speech_recognition as sr\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_name = \"charris/hubert_process_filter_spotify\"\n",
    "output_dir = \"C:/Users/joey_/Desktop/Spotify/downloaded_audio\"\n",
    "transcriptions_dir = \"C:/Users/joey_/Desktop/Spotify/transcriptions\"\n",
    "\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(transcriptions_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def download_audio_files():\n",
    "    print(f\"Cargando dataset desde {dataset_name}...\")\n",
    "    dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "    \n",
    "    # Prueba si el dataset tiene datos\n",
    "    first_sample = next(iter(dataset), None)\n",
    "    if first_sample is None:\n",
    "        print(\"Error: El dataset está vacío o no se pudo cargar.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Primer muestra del dataset:\", first_sample)  # Inspecciona la estructura\n",
    "    \n",
    "    max_files = 10\n",
    "    for i, sample in enumerate(dataset):\n",
    "        if i >= max_files:\n",
    "            break\n",
    "        try:\n",
    "            audio_data = sample[\"audio\"]\n",
    "            audio_path = audio_data[\"path\"]\n",
    "            audio_array = audio_data[\"array\"]\n",
    "            sampling_rate = audio_data[\"sampling_rate\"]\n",
    "            \n",
    "            local_path = os.path.join(output_dir, f\"audio_{i}.wav\")\n",
    "            torchaudio.save(local_path, torch.from_numpy(audio_array).unsqueeze(0), sampling_rate)\n",
    "            print(f\"Descargado: {local_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar el archivo {audio_path}: {e}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "def transcribe_with_whisper(audio_path, model):\n",
    "    print(f\"Transcribiendo {audio_path} con Whisper...\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    transcription = result[\"text\"]\n",
    "    return transcription\n",
    "\n",
    "def transcribe_with_speech_recognition(audio_path):\n",
    "    print(f\"Transcribiendo {audio_path} con SpeechRecognition...\")\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        transcription = recognizer.recognize_google(audio)\n",
    "        return transcription\n",
    "    except sr.UnknownValueError:\n",
    "        return \"No se pudo entender el audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Error en la solicitud: {e}\"\n",
    "\n",
    "def process_dataset():\n",
    "    audio_dir = download_audio_files()\n",
    "    whisper_model = whisper.load_model(\"base\")\n",
    "    for audio_file in Path(audio_dir).glob(\"*.wav\"):\n",
    "        transcription_whisper = transcribe_with_whisper(str(audio_file), whisper_model)\n",
    "        transcription_file_whisper = Path(transcriptions_dir) / f\"{audio_file.stem}_whisper.txt\"\n",
    "        transcription_file_whisper.write_text(transcription_whisper, encoding=\"utf-8\")\n",
    "        print(f\"Transcripción (Whisper) guardada en: {transcription_file_whisper}\")\n",
    "        \n",
    "        transcription_sr = transcribe_with_speech_recognition(str(audio_file))\n",
    "        transcription_file_sr = Path(transcriptions_dir) / f\"{audio_file.stem}_sr.txt\"\n",
    "        transcription_file_sr.write_text(transcription_sr, encoding=\"utf-8\")\n",
    "        print(f\"Transcripción (SpeechRecognition) guardada en: {transcription_file_sr}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Goku_SSJ4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
