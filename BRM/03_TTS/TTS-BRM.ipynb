{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT TO SPEECH FROM \"https://huggingface.co/datasets/charris/hubert_process_filter_spotify\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 17:56:11,554 - INFO - Loading dataset from charris/hubert_process_filter_spotify...\n",
      "2025-03-06 17:56:28,556 - INFO - Processing audio files...\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]2025-03-06 17:56:32,218 - INFO - Downloaded and converted: C:\\Users\\joey_\\Desktop\\Spotify\\downloaded_audio\\audio_0.wav\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.62s/it]\n",
      "2025-03-06 17:56:37,395 - INFO - Transcribing C:\\Users\\joey_\\Desktop\\Spotify\\downloaded_audio\\audio_0.wav with Whisper...\n",
      "2025-03-06 17:56:37,398 - INFO - File exists and is readable: C:\\Users\\joey_\\Desktop\\Spotify\\downloaded_audio\\audio_0.wav\n",
      "2025-03-06 17:56:37,434 - INFO - Audio loaded successfully: (496000,), sample_rate=16000\n",
      "2025-03-06 17:57:04,946 - INFO - Whisper transcription completed\n",
      "2025-03-06 17:57:04,948 - INFO - Transcribing C:\\Users\\joey_\\Desktop\\Spotify\\downloaded_audio\\audio_0.wav with SpeechRecognition...\n",
      "2025-03-06 17:57:19,374 - INFO - Transcription saved: C:\\Users\\joey_\\Desktop\\Spotify\\transcriptions\\audio_0_whisper.txt\n",
      "2025-03-06 17:57:19,376 - INFO - Transcription saved: C:\\Users\\joey_\\Desktop\\Spotify\\transcriptions\\audio_0_speech_recognition.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import time\n",
    "from typing import Optional, Dict, Any\n",
    "from datasets import load_dataset\n",
    "import torchaudio\n",
    "import torch\n",
    "import whisper\n",
    "import speech_recognition as sr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import librosa  # Re-added for audio loading\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"dataset_name\": \"charris/hubert_process_filter_spotify\",\n",
    "    \"output_dir\": Path(\"C:/Users/joey_/Desktop/Spotify/downloaded_audio\"),\n",
    "    \"transcriptions_dir\": Path(\"C:/Users/joey_/Desktop/Spotify/transcriptions\"),\n",
    "    \"max_files\": 1,\n",
    "    \"whisper_model\": \"base\",\n",
    "    \"num_workers\": 2\n",
    "}\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('transcription.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def setup_directories() -> None:\n",
    "    \"\"\"Create necessary directories if they don't exist.\"\"\"\n",
    "    CONFIG[\"output_dir\"].mkdir(parents=True, exist_ok=True)\n",
    "    CONFIG[\"transcriptions_dir\"].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def download_audio_files() -> Optional[Path]:\n",
    "    \"\"\"Download and save audio files from the dataset.\"\"\"\n",
    "    logging.info(f\"Loading dataset from {CONFIG['dataset_name']}...\")\n",
    "    try:\n",
    "        dataset = load_dataset(CONFIG[\"dataset_name\"], split=\"train\", streaming=False)\n",
    "        first_sample = next(iter(dataset), None)\n",
    "        \n",
    "        if first_sample is None:\n",
    "            logging.error(\"Dataset is empty or could not be loaded.\")\n",
    "            return None\n",
    "        \n",
    "        logging.info(\"Processing audio files...\")\n",
    "        for i, sample in tqdm(enumerate(dataset), total=CONFIG[\"max_files\"]):\n",
    "            if i >= CONFIG[\"max_files\"]:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                audio_data = sample[\"audio\"]\n",
    "                local_path = CONFIG[\"output_dir\"] / f\"audio_{i}.wav\"\n",
    "                \n",
    "                audio_array = torch.from_numpy(audio_data[\"array\"]).unsqueeze(0)\n",
    "                audio_array = (audio_array * 32767).to(torch.int16)\n",
    "                \n",
    "                torchaudio.save(\n",
    "                    str(local_path),\n",
    "                    audio_array,\n",
    "                    audio_data[\"sampling_rate\"],\n",
    "                    encoding='PCM_S',\n",
    "                    bits_per_sample=16\n",
    "                )\n",
    "                time.sleep(2)\n",
    "                logging.info(f\"Downloaded and converted: {local_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing file {i}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return CONFIG[\"output_dir\"]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to download audio files: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_with_whisper(audio_path: str, model: Any) -> str:\n",
    "    \"\"\"Transcribe audio using Whisper model.\"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Transcribing {audio_path} with Whisper...\")\n",
    "        if not os.path.isfile(audio_path):\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
    "        if not os.access(audio_path, os.R_OK):\n",
    "            raise PermissionError(f\"No read permission for file: {audio_path}\")\n",
    "        \n",
    "        logging.info(f\"File exists and is readable: {audio_path}\")\n",
    "        \n",
    "        # Load audio as an array to bypass file path issues\n",
    "        audio, sample_rate = librosa.load(audio_path, sr=16000)  # Whisper expects 16kHz\n",
    "        logging.info(f\"Audio loaded successfully: {audio.shape}, sample_rate={sample_rate}\")\n",
    "        \n",
    "        # Transcribe using the audio array instead of the file path\n",
    "        result = model.transcribe(audio)\n",
    "        logging.info(\"Whisper transcription completed\")\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Whisper transcription failed: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def transcribe_with_speech_recognition(audio_path: str) -> str:\n",
    "    \"\"\"Transcribe audio using Google Speech Recognition.\"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Transcribing {audio_path} with SpeechRecognition...\")\n",
    "        if not os.path.isfile(audio_path):\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
    "        \n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        logging.warning(f\"Could not understand audio: {audio_path}\")\n",
    "        return \"Audio could not be understood\"\n",
    "    except sr.RequestError as e:\n",
    "        logging.error(f\"Speech Recognition service error: {str(e)}\")\n",
    "        return f\"Service error: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error in speech recognition: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_single_file(audio_file: Path, whisper_model: Any) -> Dict[str, str]:\n",
    "    \"\"\"Process a single audio file with both transcription methods.\"\"\"\n",
    "    results = {}\n",
    "    results[\"whisper\"] = transcribe_with_whisper(str(audio_file), whisper_model)\n",
    "    results[\"speech_recognition\"] = transcribe_with_speech_recognition(str(audio_file))\n",
    "    return results\n",
    "\n",
    "def save_transcriptions(audio_file: Path, transcriptions: Dict[str, str]) -> None:\n",
    "    \"\"\"Save transcriptions to files.\"\"\"\n",
    "    for method, text in transcriptions.items():\n",
    "        output_file = CONFIG[\"transcriptions_dir\"] / f\"{audio_file.stem}_{method}.txt\"\n",
    "        try:\n",
    "            output_file.write_text(text, encoding=\"utf-8\")\n",
    "            logging.info(f\"Transcription saved: {output_file}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to save transcription: {str(e)}\")\n",
    "\n",
    "def process_dataset() -> None:\n",
    "    \"\"\"Main function to process the dataset.\"\"\"\n",
    "    setup_directories()\n",
    "    audio_dir = download_audio_files()\n",
    "    \n",
    "    if not audio_dir:\n",
    "        logging.error(\"Failed to process dataset\")\n",
    "        return\n",
    "\n",
    "    whisper_model = whisper.load_model(CONFIG[\"whisper_model\"])\n",
    "    audio_files = list(Path(audio_dir).glob(\"*.wav\"))\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        while not os.path.exists(audio_file) or not os.access(audio_file, os.R_OK):\n",
    "            logging.info(f\"Waiting for {audio_file} to be fully written and readable...\")\n",
    "            time.sleep(1)\n",
    "        \n",
    "        transcriptions = process_single_file(audio_file, whisper_model)\n",
    "        save_transcriptions(audio_file, transcriptions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        process_dataset()\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"Process interrupted by user\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Goku_SSJ4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
